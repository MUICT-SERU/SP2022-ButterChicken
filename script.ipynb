{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get BM25 recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='error.log', level=logging.ERROR)\n",
    "from datetime import datetime\n",
    "FILES = [\n",
    "    \"grandmaster_nl_pl_only_plot.json\",\n",
    "    \"master_nl_pl_only_plot.json\",\n",
    "    \"expert_nl_pl_only_plot.json\",\n",
    "]\n",
    "\n",
    "CLASS_NAME = {\n",
    "    \"grandmaster\": \"GrandMasterCode\",\n",
    "    \"master\": \"MasterCode\",\n",
    "    \"expert\": \"ExpertCode\",\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weaviate Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import loads\n",
    "import weaviate\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "weaviate_client = weaviate.Client(\"http://202.151.177.149:81\")  # Replace with your endpoint\n",
    "some_objects = weaviate_client.data_object.get()\n",
    "if (json.dumps(some_objects)):\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "\n",
    "print(json.dumps(some_objects))\n",
    "\n",
    "\n",
    "elastic_client = Elasticsearch(\"http://202.151.177.154:9200\")\n",
    "\n",
    "response = str(elastic_client.info())\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMLRecommendation(text: str, target_class: str) -> dict:\n",
    "    # md_text = obj['markdown']\n",
    "    # cur_class = \"grandmaster\"\n",
    "    near_text = {\"concepts\": [text]}\n",
    "    fetched = (weaviate_client.query\n",
    "                      .get(CLASS_NAME[target_class], [\"code\"])\n",
    "                      .with_near_text(near_text)\n",
    "                      .with_limit(1)\n",
    "                      .do()\n",
    "                      )\n",
    "    data = fetched['data']['Get'][CLASS_NAME[target_class]]\n",
    "    return data[0]\n",
    "\n",
    "def getElasticQuery(query, type=[\"base\", \"processed\"]):\n",
    "    if (type == \"processed\"):\n",
    "        result = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"processed\": {\n",
    "                    \"query\": query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    else:\n",
    "        result = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"markdown\": {\n",
    "                    \"query\": query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return result \n",
    "\n",
    "def getElasticRecommendation(index, queryBody):\n",
    "    response = elastic_client.search(index=index, body=queryBody)\n",
    "\n",
    "    if response and response[\"hits\"][\"hits\"]:\n",
    "        result = response[\"hits\"][\"hits\"][0][\"_source\"]\n",
    "        return result\n",
    "    return []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load recommendation result into JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_name in FILES:\n",
    "#     with open(f'data/{file_name}', 'r') as file:\n",
    "#         data = json.load(file)\n",
    "#         data_rank = file_name[:-21]\n",
    "\n",
    "#         data_length = len(data)\n",
    "#         testing_accumulate = []\n",
    "#         count = 0\n",
    "        \n",
    "\n",
    "#         for row in data:\n",
    "#             if (count>=1):\n",
    "#                 break\n",
    "            \n",
    "#             markdown = \"\".join(row['markdown'])\n",
    "            \n",
    "#             try:\n",
    "#                 temp_result = {\n",
    "#                     \"original_md\": markdown,\n",
    "#                     \"original_code\": row['code'],\n",
    "#                     \"count\": count,\n",
    "#                     \"data_rank\": data_rank\n",
    "#                 }\n",
    "\n",
    "#                 es_query = getElasticQuery(markdown)\n",
    "#                 es_result = getElasticRecommendation(data_rank, es_query)\n",
    "#                 es_result = json.dumps(es_result, indent=4)\n",
    "#                 print(es_result)\n",
    "\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f'[{datetime.now().strftime(\"%d/%m/%y %H:%M:%S\")}] Skipping item #{count} due to an error.')\n",
    "#                 logging.error(f\"Error occurred for item: {markdown}\\nError message: {str(e)}\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\n\")\n",
    "#                 continue\n",
    "#             count =  count + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in FILES:\n",
    "    with open(f'data/{file_name}', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        data_rank = file_name[:-21]\n",
    "\n",
    "        data_length = len(data)\n",
    "        testing_accumulate = []\n",
    "        count = 0\n",
    "        for row in data:\n",
    "\n",
    "            markdown = \"\".join(row['markdown'])\n",
    "            \n",
    "            print(f\"markdown length: {len(markdown)}\")\n",
    "            try:\n",
    "\n",
    "                temp_result = {\n",
    "                    \"running_count_label\": count,\n",
    "                    \"data_rank\": data_rank,\n",
    "                    \"original\": {\n",
    "                        \"markdown\": markdown,\n",
    "                        \"code\": row['code'],\n",
    "                        \"processed_markdown\": row['processed'],\n",
    "                    },\n",
    "                    # Template for insert\n",
    "                    \"mlRecommendation\": {\n",
    "                        \"code\": \"\"\n",
    "                    },\n",
    "                    \"bm25Recommendation\": {\n",
    "                        \"markdown\": \"\",\n",
    "                        \"processed_markdown\": \"\",\n",
    "                        \"code\": \"\",\n",
    "                    },\n",
    "                    \"bm25ProcessedRecommendation\": {\n",
    "                        \"markdown\": \"\",\n",
    "                        \"processed_markdown\": \"\",\n",
    "                        \"code\": \"\"\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                # Get ML Recommendation\n",
    "                recommended_code_ml = getMLRecommendation(markdown, data_rank)\n",
    "                temp_result[\"mlRecommendation\"][\"code\"] = recommended_code_ml['code']\n",
    "            \n",
    "                # Get Elastic Recommendation\n",
    "                query_base = getElasticQuery(markdown)\n",
    "                query_processed = getElasticQuery(markdown, \"processed\")\n",
    "\n",
    "                recommended_code_es_base = getElasticRecommendation(data_rank, query_base)\n",
    "                recommended_code_es_processed = getElasticRecommendation(data_rank, query_processed)\n",
    "\n",
    "                temp_result[\"bm25Recommendation\"][\"markdown\"] = recommended_code_es_base['markdown']\n",
    "                temp_result[\"bm25Recommendation\"][\"processed_markdown\"] = recommended_code_es_base['processed']\n",
    "                temp_result[\"bm25Recommendation\"][\"code\"] = recommended_code_es_base['code']\n",
    "\n",
    "                temp_result[\"bm25ProcessedRecommendation\"][\"markdown\"] = recommended_code_es_processed['markdown']\n",
    "                temp_result[\"bm25ProcessedRecommendation\"][\"processed_markdown\"] = recommended_code_es_processed['processed']\n",
    "                temp_result[\"bm25ProcessedRecommendation\"][\"code\"] = recommended_code_es_processed['code']\n",
    "\n",
    "                # Append to the collection\n",
    "                testing_accumulate.append(temp_result)\n",
    "\n",
    "                print(f'Count: {count}/{data_length}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'[{datetime.now().strftime(\"%d/%m/%y %H:%M:%S\")}] Skipping item #{count} due to an error.')\n",
    "                logging.error(f\"Error occurred for item: {markdown}\\nError message: {str(e)}\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\\n\")\n",
    "                continue\n",
    "            count =  count + 1\n",
    "        \n",
    "        with open(f\"recommendation-result/{data_rank}_result.json\", \"w\") as file:\n",
    "            json.dump(testing_accumulate, file)\n",
    "            print(f\"successfully write to: {data_rank}_result.json \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing original with recommended ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_NAMES = [\n",
    "#     \"grandmaster_result.json\",\n",
    "#     \"master_result.json\",\n",
    "#     \"expert_result.json\",\n",
    "# ]\n",
    "\n",
    "# for name in FILE_NAMES:\n",
    "#     path = f\"recommendation-result/{name}\"\n",
    "#     data_rank = name[:-12]\n",
    "\n",
    "#     with open(path, 'r') as file:\n",
    "#         original_file_path = open(f'data/{data_rank}_nl_pl_only_plot.json')\n",
    "#         original_data = json.load(original_file_path)\n",
    "\n",
    "#         data = json.load(file)\n",
    "\n",
    "#         print(f\"rank {data_rank}: {len(data)} items || original : {len(original_data)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "metadata = {}\n",
    "FILE_NAMES = [\n",
    "    \"grandmaster_result.json\",\n",
    "    \"master_result.json\",\n",
    "    \"expert_result.json\",\n",
    "]\n",
    "for name in FILE_NAMES:\n",
    "    path = f\"recommendation-result/{name}\"\n",
    "    data_rank = name[:-12]\n",
    "\n",
    "    with open(path, 'r') as file:\n",
    "        original_file_path = open(f'data/{data_rank}_nl_pl_only_plot.json')\n",
    "        original_data = json.load(original_file_path)\n",
    "        \n",
    "        data = json.load(file)\n",
    "        print(f\"rank {data_rank}: {len(data)} items || original : {len(original_data)} items\")\n",
    "\n",
    "        comparison_collection = {\n",
    "            \"ml\": 0,\n",
    "            \"es\": 0,\n",
    "            \"es-processed\": 0,\n",
    "        }\n",
    "        incorrect_summarize = {\n",
    "            # \"ml\": 0,\n",
    "            \"es\": 0,\n",
    "            # \"es-processed\": 0,\n",
    "        }\n",
    "\n",
    "        incorrect_pairs = []\n",
    "        incorrect = {\n",
    "\n",
    "        }\n",
    "        i = 0\n",
    "        count_empty = 0\n",
    "        for item in data:\n",
    "            if (not item['original']['markdown']):\n",
    "                count_empty = count_empty + 1\n",
    "                continue\n",
    "\n",
    "            ml_recommendation = item['mlRecommendation']\n",
    "            bm25_base_recommendation = item['bm25Recommendation']\n",
    "            bm25_processed_recommendation = item['bm25ProcessedRecommendation']\n",
    "            \n",
    "            original = item['original']\n",
    "\n",
    "            # ML\n",
    "            if (original['code']==ml_recommendation['code']):\n",
    "                comparison_collection[\"ml\"] = comparison_collection[\"ml\"] + 1\n",
    "            \n",
    "            # BM25 processeds\n",
    "            if (original['code']==bm25_processed_recommendation['code']):\n",
    "                comparison_collection[\"es-processed\"] = comparison_collection[\"es-processed\"] + 1\n",
    "\n",
    "            # BM25 base\n",
    "            if (original['code']==bm25_base_recommendation['code']):\n",
    "                comparison_collection[\"es\"] = comparison_collection[\"es\"] + 1\n",
    "            else:                \n",
    "                incorrect_summarize[\"es\"] = incorrect_summarize[\"es\"] + 1\n",
    "                incorrect_pairs.append({\n",
    "                    \"original_markdown\": original['markdown'],\n",
    "                    \"original_code\": original['code'],\n",
    "                    \"bm25_markdown\": bm25_base_recommendation['markdown'],\n",
    "                    \"bm25_code\": bm25_base_recommendation['code'],\n",
    "                    \"ml_code\": ml_recommendation['code']\n",
    "                })\n",
    "        \n",
    "        print(f\"Skipped {count_empty} empty Markdown items in rank {data_rank}\")\n",
    "        \n",
    "        output[data_rank] = {\n",
    "            \"correct_pairs_summarize\": comparison_collection,\n",
    "            \"incorrect_summarize\": {\n",
    "                \"es\": len(data)-count_empty-comparison_collection[\"es\"]\n",
    "            },\n",
    "            \"incorrect_pairs_items\": incorrect_pairs,\n",
    "        }\n",
    "\n",
    "        metadata[data_rank] = {\n",
    "            \"total_items\": len(data),\n",
    "            \"total_skipped_empty_markdown\": count_empty,\n",
    "            \"total_es_correct_pairs_\": comparison_collection[\"es\"],\n",
    "            \"total_es_incorrect_pairs_\": incorrect_summarize[\"es\"]\n",
    "        }\n",
    "        \n",
    "with open(f\"comparison_result.json\", \"w\") as file:\n",
    "    output = json.dump(output, file)\n",
    "    print(f'successfully write to /result/comparison_result.json')\n",
    "print(\"Done!!\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Summarize:\n",
    "\n",
    "Rank Grandmaster\n",
    "- Total items: {metadata['grandmaster'][\"total_items\"]}\n",
    "- Total skipped empty Markdown: {metadata['grandmaster'][\"total_skipped_empty_markdown\"]}\n",
    "# Below is only for Elasticsearch base approach #\n",
    "- Total correct original-recommended pairs: {metadata['grandmaster'][\"total_es_correct_pairs_\"]}\n",
    "- Total incorrect original-recommended pairs: {metadata['grandmaster'][\"total_es_incorrect_pairs_\"]}\n",
    "\n",
    "Rank Master\n",
    "- Total items: {metadata['master'][\"total_items\"]}\n",
    "- Total skipped empty Markdown: {metadata['master'][\"total_skipped_empty_markdown\"]}\n",
    "# Below is only for Elasticsearch base approach #\n",
    "- Total correct original-recommended pairs: {metadata['master'][\"total_es_correct_pairs_\"]}\n",
    "- Total incorrect original-recommended pairs: {metadata['master'][\"total_es_incorrect_pairs_\"]}\n",
    "\n",
    "Rank Expert\n",
    "- Total items: {metadata['expert'][\"total_items\"]}\n",
    "- Total skipped empty Markdown: {metadata['expert'][\"total_skipped_empty_markdown\"]}\n",
    "# Below is only for Elasticsearch base approach #\n",
    "- Total correct original-recommended pairs: {metadata['expert'][\"total_es_correct_pairs_\"]}\n",
    "- Total incorrect original-recommended pairs: {metadata['expert'][\"total_es_incorrect_pairs_\"]}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter and take some sample of data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "RANKS = ['grandmaster', 'master', 'expert']\n",
    "MAX_SAMPLE = 5\n",
    "\n",
    "with open(\"comparison_result.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    for rank in RANKS:\n",
    "        incorrect_pairs = data[rank]['incorrect_pairs_items']\n",
    "        with open(f'./analysis-result/{rank}_analysis.txt', 'w', encoding=\"utf-8\") as file:\n",
    "            random_range = list(range(0, len(incorrect_pairs)))\n",
    "            random.shuffle(random_range)\n",
    "            i = 0\n",
    "            while i<MAX_SAMPLE:\n",
    "                if (i>=MAX_SAMPLE):\n",
    "                    break\n",
    "                print(f\"i = {i}\")\n",
    "\n",
    "                file.write(f\"ITEM #{i+1}\\n\\n\")\n",
    "                file.write(f\"ORIGINAL MARKDOWN:\\n{'-'*30}\\n\")\n",
    "                file.write(str(incorrect_pairs[i]['original_markdown']))\n",
    "                file.write(f\"\\n{'='*30}\\n\")\n",
    "\n",
    "                file.write(f\"RECOMMENDED MARKDOWN:\\n{'-'*30}\\n\")\n",
    "                file.write(str(incorrect_pairs[i]['bm25_markdown'][0]))\n",
    "                file.write(f\"\\n{'='*30}\\n\")\n",
    "                \n",
    "                file.write(f\"ORIGINAL CODE:\\n{'-'*30}\\n\")\n",
    "                file.write(str(incorrect_pairs[i]['original_code']))\n",
    "                file.write(f\"\\n{'='*30}\\n\")\n",
    "                \n",
    "                file.write(f\"RECOMMENDED CODE:\\n{'-'*30}\\n\")\n",
    "                file.write(str(incorrect_pairs[i]['bm25_code']))\n",
    "                file.write(f\"\\n{'='*30}\\n\")\n",
    "\n",
    "                file.write(f\"RECOMMENDED MACHINE LEARNING CODE:\\n{'-'*30}\\n\")\n",
    "                file.write(str(incorrect_pairs[i]['ml_code']))\n",
    "                file.write(\"\\n\" + \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\"*2 + \"\\n\")\n",
    "\n",
    "                i = i+1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
