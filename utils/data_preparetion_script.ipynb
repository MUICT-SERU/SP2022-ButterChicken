{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47ac3ac-7b72-4fb8-8d21-0033e6696b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6c7d04-46b2-4359-b287-3a8b0da949d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/100 files are copied from Competition 10385.\n",
      "92/100 files are copied from Competition 14242.\n",
      "65/100 files are copied from Competition 9120.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve Files from dataset\n",
    "headers = ['File Name','Competition ID','Kernel Created Date', 'Votes']\n",
    "\n",
    "abs_path = '/home/ictstudent/ButterChicken/Data Preparation/'\n",
    "notebook_lists_path = 'Notebook Lists'\n",
    "os.chdir(abs_path + notebook_lists_path)\n",
    "\n",
    "comp_id_mapping = {}\n",
    "\n",
    "retrieve_files = {}\n",
    "notebook_lists = os.listdir('.')\n",
    "\n",
    "# Chapter 3: Evaluation\n",
    "avoid_list = [\n",
    "    \"gpreda_santander-eda-and-prediction.ipynb\",\n",
    "    \"artgor_eda-and-models.ipynb\",\n",
    "]\n",
    "\n",
    "for notebook_list in notebook_lists:\n",
    "    if notebook_list[-4:] == '.csv':\n",
    "        file_count = 0\n",
    "        with open(notebook_list, 'r') as file:\n",
    "            data = csv.reader(file, delimiter=',')\n",
    "            comp_id = next(data)[1]\n",
    "            comp_id_mapping[notebook_list] = comp_id\n",
    "        # end with\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "for notebook_list in notebook_lists:\n",
    "    if notebook_list[-4:] == '.csv':\n",
    "        file_count = 0\n",
    "        with open(notebook_list, 'r') as file:\n",
    "            data = csv.reader(file, delimiter=',')\n",
    "            comp_id = comp_id_mapping[notebook_list]\n",
    "            comp_id_path = '../Competitions/' + comp_id\n",
    "            \n",
    "            if os.path.exists(comp_id_path):\n",
    "                os.system('rm -rf ' + comp_id_path)\n",
    "            # end if\n",
    "            \n",
    "            if not os.path.exists(comp_id_path):\n",
    "                os.system('mkdir ' + comp_id_path)\n",
    "            # end if\n",
    "            \n",
    "            for row in data:\n",
    "                if row[0] in avoid_list: continue\n",
    "                notebook_path = '../../../KGTorrent/KT_dataset/' + row[0]\n",
    "                command = 'cp ' + notebook_path + ' ' + comp_id_path\n",
    "                if os.path.exists(notebook_path):\n",
    "                    os.system(command)\n",
    "                    file_count = file_count + 1\n",
    "                # end if\n",
    "            # end for\n",
    "            retrieve_files[comp_id] = file_count\n",
    "        # end with\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "total_files = 0\n",
    "\n",
    "for key in retrieve_files:\n",
    "    each_comp_files = retrieve_files[key]\n",
    "    total_files = total_files + each_comp_files\n",
    "    print(str(each_comp_files) + '/100 files are copied from Competition ' + str(key) + '.');\n",
    "#end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680ee366-b83b-49cc-94b7-7c4be06a9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_notebook(index, file_path):\n",
    "    code = ''\n",
    "    found_code = False\n",
    "    markdown_list = []\n",
    "    md_code_pair = []\n",
    "    \n",
    "    file = codecs.open(file_path, 'r')\n",
    "    source = file.read()\n",
    "    notebook = json.loads(source)\n",
    "\n",
    "    for row in notebook['cells']:\n",
    "        markdown = ''\n",
    "                \n",
    "        if row['cell_type'] == 'markdown':\n",
    "            if found_code:\n",
    "                md_code_pair.append({'markdown': markdown_list , 'code': code})\n",
    "                code = ''\n",
    "                markdown_list = []\n",
    "                index = index + 1\n",
    "            # end if\n",
    "            \n",
    "            for line in row['source']:            \n",
    "                markdown = markdown + line\n",
    "            # end for\n",
    "            found_code = False\n",
    "            markdown_list.append(markdown)    \n",
    "        # end if\n",
    "            \n",
    "        if row['cell_type'] == 'code':\n",
    "            if found_code:\n",
    "                code = code + '\\n'\n",
    "            # end if\n",
    "\n",
    "            for line in row['source']:\n",
    "                code = code + line\n",
    "            # end for\n",
    "            found_code = True\n",
    "        # end if\n",
    "        \n",
    "    # end for\n",
    "        \n",
    "    return index, md_code_pair\n",
    "# end def\n",
    "\n",
    "def append_path(cur, dest):\n",
    "    return cur + '/' + dest\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c253d50-ed05-4583-9deb-f4d56b51d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = []\n",
    "cur_index = 0\n",
    "\n",
    "non_code_notebooks = []\n",
    "\n",
    "path = abs_path + 'Competitions'\n",
    "os.chdir(path)\n",
    "competitions = os.listdir('.')\n",
    "\n",
    "for competition in competitions:\n",
    "    if os.path.isdir(competition):\n",
    "        notebooks = os.listdir(competition)\n",
    "        comp_path = append_path(path, competition)\n",
    "        \n",
    "        for notebook in notebooks:\n",
    "            if notebook[-6:] == '.ipynb':\n",
    "                notebook_path = append_path(comp_path, notebook)\n",
    "                with open(notebook_path, 'r') as file:\n",
    "                    cur_index, output = extract_notebook(cur_index, notebook_path)\n",
    "                    if output == []:\n",
    "                        non_code_notebooks.append(notebook_path)\n",
    "                    else:\n",
    "                        for pair in output:\n",
    "                            all_pairs.append(pair)\n",
    "                        # end for\n",
    "                    # end if\n",
    "                # end with\n",
    "        # end for\n",
    "    # end if\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7d8dcf-8a4e-4d00-837e-9b2b6c0c2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_name = '../nl_pl_pairs_chap3.json'\n",
    "\n",
    "with open(json_file_name, 'w+') as output_file:\n",
    "    json.dump(all_pairs, output_file)\n",
    "# end with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f914013-9b9d-4f0b-a13d-ad2cf7e3b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49 notebooks which are not contain any code cell.\n",
      "The output JSON file is created from 185/234 notebooks.\n"
     ]
    }
   ],
   "source": [
    "non_code_files = len(non_code_notebooks)\n",
    "\n",
    "print('There are ' + str(non_code_files) + ' notebooks which are not contain any code cell.')\n",
    "print('The output JSON file is created from ' + \n",
    "      str(total_files - non_code_files)+ '/' + str(total_files) + ' notebooks.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95304e38-1f7a-4e1d-9f9e-a4c345410c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
