{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10385', '14242', '9120']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abs_path = r'/home/ictstudent/ButterChicken/Data Preparation'\n",
    "abs_path = r'C:\\Users\\Veera\\Desktop\\Senior\\SP2022-ButterChicken\\Data Preparation'\n",
    "\n",
    "# print(os.getcwd())\n",
    "competition_directories = os.listdir(f'{abs_path}/Competitions')\n",
    "competition_list = []\n",
    "\n",
    "for competition in competition_directories:\n",
    "    # print(competition.isnumeric())\n",
    "    if competition.isnumeric():\n",
    "        competition_list.append(competition)\n",
    "\n",
    "competition_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[.ipynb_checkpoints] directory not present in competition id [10385]\n",
      "[.ipynb_checkpoints] directory not present in competition id [14242]\n",
      "Total number of notebooks: 234\n"
     ]
    }
   ],
   "source": [
    "count_competition = 0\n",
    "for item in competition_list:\n",
    "    competition_dir = f'{abs_path}/Competitions/{item}'\n",
    "    directory_list = os.listdir(competition_dir)\n",
    "    try: \n",
    "        directory_list.remove('.ipynb_checkpoints')\n",
    "    except: \n",
    "        print(f'[.ipynb_checkpoints] directory not present in competition id [{item}]')\n",
    "    count_competition = count_competition + len(directory_list)\n",
    "    \n",
    "print(f'Total number of notebooks: {count_competition}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_markdown(file_path):\n",
    "    file = codecs.open(file_path, 'r', encoding=\"utf8\")\n",
    "    source = file.read()\n",
    "    notebook = json.loads(source)\n",
    "\n",
    "    inner_count = -1\n",
    "    index = 0\n",
    "    found_code = False\n",
    "    markdown_list = []\n",
    "    for row in notebook['cells']:\n",
    "        inner_count = inner_count + 1\n",
    "        if row['cell_type'] == 'code':\n",
    "            found_code = True\n",
    "            continue\n",
    "\n",
    "        markdown_res = {\n",
    "            \"index\": index,\n",
    "            \"markdown\": row['source'],\n",
    "        }\n",
    "        markdown_list.append(markdown_res)\n",
    "        index = index + 1\n",
    "    return markdown_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_collection = []\n",
    "\n",
    "for competition_id in competition_list:\n",
    "    for notebook in os.listdir(f'{abs_path}/Competitions/{competition_id}'):\n",
    "        author_name, notebook_title = notebook.split('_')\n",
    "        notebook_title = notebook_title[:-6]\n",
    "\n",
    "        if notebook == '.ipynb_checkpoints': \n",
    "            continue\n",
    "        \n",
    "        file_path = f'{abs_path}/Competitions/{competition_id}/{notebook}'\n",
    "\n",
    "        extracted_results = extract_markdown(file_path)\n",
    "        \n",
    "        markdown_list = [i['markdown'] for i in extracted_results]\n",
    "        index_list = [i['index'] for i in extracted_results]\n",
    "        markdownIndex_list = [author_name+'_'+notebook_title+'_m'+str(i['index']) for i in extracted_results]\n",
    "        \n",
    "        results = list(zip(markdown_list, index_list, [author_name for i in range(0, len(extracted_results))], [notebook_title for i in range(0, len(extracted_results))], markdownIndex_list))\n",
    "        markdown_collection = markdown_collection + results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['markdown_content', 'index_in_notebook', 'author_name', 'notebook_title', 'markdown_key']\n",
    "with open('./markdown-index.csv', 'w', encoding='utf8', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(markdown_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senior-jupyter",
   "language": "python",
   "name": "senior-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf5f69b3c1e18f509bc3e5784158a91a8d5962c26b685adcaa8318167674423f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
