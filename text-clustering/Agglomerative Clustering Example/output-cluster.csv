cluster-assignment,text-data
0,gener inform in thi kernel i work with ieee fraud detect competit eee ci work across a varieti of ai and machin learn area includ deep neural network fuzzi system evolutionari comput and swarm intellig today they’r partner with the world’ lead payment servic compani vesta corpor seek the best solut for fraud prevent industri and now you are invit to join the challeng we have a binari classif problem with a heavi imbal which is an inher properti of such problem at first i ll explor the data and tri to find valuabl insight mayb i ll do some featur engin and then it wil be time to build model work in progress
1,import librari
0,function use in thi kernel they are in the hidden cell below
0,data load and overview data is separ into two dataset inform about the ident of the custom and transact inform not all transact belong to ident which are avail mayb it would be possibl to use addit transact to gener new featur
0,so we have two medium size dataset with a lot of column train and test data have similar number of row
0,most of column have miss data which is normal in real world also there are column with one uniqu valu or all miss there are a lot of continu variabl and some categor let s have a closer look at them
0,data explor let s start with ident inform id 01 id 11 are continu variabl id 12 id 38 are categor and the last two column are obvious also categor
0,id 01 ha an interest distribut it ha 77 uniqu non posit valu with skew to 0
0,id 03 ha 88 of miss valu and 98 of valu are either miss or equal to 0
0,22 of valu in id 11 are equal to 100and 76 are miss quit strang
0,some of featur seem to be normal so if someon want to normal all variabl it would be necessari to separ such variabl which seem to be alreadi normal
0,we have sever featur show some kind of found statu and sever binari column
0,here we can see some inform about client s devic it is import to be care here some of info could be for old devic and may be absent from test data now let s have a look at transact data
0,a veri import idea it seem that train and test transact date don t overlap so it would be prudent to use time base split for valid thi wa alreadi note in aboth kernel
0,so card6 is type of card card4 is credit card compani
0,featur engin let s creat some aggreg there is no logic in them simpli aggreg on top featur
0,prepar data for model
2,lgbm
3,blend
0,santand eda and predict dataset use santand custom transact predict content introduct prepar the data analysi data explor check the data densiti plot of featur distribut of mean and std distribut of min and max distribut of skew and kurtosi featur correl duplic valu featur engin model submiss refer
0,introduct in thi challeng santand invit kaggler to help them identifi which custom will make a specif transact in the futur irrespect of the amount of money transact the data provid for thi competit ha the same structur a the real data they have avail to solv thi problem the data is anonimyz each row contain 200 numer valu identifi just with a number in the follow we will explor the data prepar it for a model train a model and predict the target valu for the test set then prepar a submiss stay tune i will frequent updat thi kernel in the next day
0,prepar for data analysi load packag
0,load data let s check what data file are avail
0,let s load the train and test data file
0,data explor check the data let s check the train and test set
0,both train and test data have 200 000 entri and 202 respectivelli 201 column let s glimps train and test dataset
0,train contain id code string target 200 numer variabl name from var 0 to var 199 test contain id code string 200 numer variabl name from var 0 to var 199 let s check if there are ani miss data we will also chech the type of data we check first train
0,here we check test dataset
0,there are no miss data in train and test dataset let s check the numer valu in train and test dataset
0,we can make few observ here standard deviat is rel larg for both train and test variabl data min max mean sdt valu for train and test data look quit close mean valu are distribut over a larg rang the number of valu in train and test set is the same let s plot the scatter plot for train and test set for few of the featur
0,we will show just 5 of the data on x axi we show train valu and on the y axi we show the test valu
0,let s check the distribut of target valu in train dataset
0,the data is unbalanc with respect with target valu
0,densiti plot of featur let s show now the densiti plot of variabl in train dataset we repres with differ color the distribut for valu with target valu 0 and 1
0,the first 100 valu are display in the follow cell press output to display the plot
0,the next 100 valu are display in the follow cell press output to display the plot
0,we can observ that there is a consider number of featur with signific differ distribut for the two target valu for exampl var 0 var 1 var 2 var 5 var 9 var 13 var 106 var 109 var 139 and mani other also some featur like var 2 var 13 var 26 var 55 var 175 var 184 var 196 show a distribut that resambl to a bivari distribut we will take thi into consider in the futur for the select of the featur for our predict model le t s now look to the distribut of the same featur in parallel in train and test dataset the first 100 valu are display in the follow cell press output to display the plot
0,the next 100 valu are display in the follow cell press output to display the plot
0,the train and test seem to be well ballanc with respect with distribut of the numer variabl distribut of mean and std let s check the distribut of the mean valu per row in the train and test set
0,let s check the distribut of the mean valu per column in the train and test set
0,let s show the distribut of standard deviat of valu per row for train and test dataset
0,let s check the distribut of the standard deviat of valu per column in the train and test dataset
0,let s check now the distribut of the mean valu per row in the train dataset group by valu of target
0,let s check now the distribut of the mean valu per column in the train dataset group by valu of target
0,distribut of min and max let s check the distribut of min per row in the train and test set
0,a long queue to the lower valu for both extend a long a to 80 for test set is observ let s now show the distribut of min per column in the train and test set
0,let s check now the distribut of max valu per row for train and test set
0,let s show now the max distribut on column for train and test set
0,let s show now the distribut of min valu per row in train set separ on the valu of target 0 and 1
0,we show here the distribut of min valu per column in train set
0,let s show now the distribut of max valu per rown in the train set
0,let s show also the distribut of max valu per column in the train set
0,distribut of skew and kurtosi let s see now what is the distribut of skew valu per row and column let s see first the distribut of skew calcul per row in train and test set
0,let s see first the distribut of skew calcul per column in train and test set
0,let s see now what is the distribut of kurtosi valu per row and column let s see first the distribut of kurtosi calcul per row in train and test set
0,let s see first the distribut of kurtosi calcul per column in train and test set
0,let s see now the distribut of skew on row in train separ for valu of target 0 and 1
0,let s see now the distribut of skew on column in train separ for valu of target 0 and 1
0,let s see now the distribut of kurtosi on row in train separ for valu of target 0 and 1
0,let s see now the distribut of kurtosi on column in train separ for valu of target 0 and 1
0,featur correl we calcul now the correl between the featur in train set the follow tabl show the first 10 the least correl featur
0,let s look to the top most correl featur besid the same featur pair
0,let s see also the least correl featur
0,the correl between the featur is veri small duplic valu let s now check how mani duplic valu exist per column
0,let s show the top 15 max of duplic valu per train set
0,let s see also the top 15 number of duplic valu per test set
0,same column in train and test set have the same or veri close number of duplic of same or veri close valu thi is an interest pattern that we might be abl to use in the futur
0,featur engin thi section is under construct let s calcul for start few aggreg valu for the exist featur
0,let s check the new creat featur
0,let s check the distribut of these new engin featur we plot first the distribut of new featur group by valu of correspond target valu
0,let s show the distribut of new featur valu for train and test
0,we add round featur note thi is a work in progress some of the featur ad here will be later drop featur c for c in train df column if c not in id code target for featur in featur train df r2 featur np round train df featur 2 test df r2 featur np round test df featur 2 train df r1 featur np round train df featur 1 test df r1 featur np round test df featur 1 let s check how mani featur we have now
0,model from the train column list we drop the id and target to form the featur list
0,we defin the hyperparamet for the model
0,we run the model
0,let s check the featur import
0,submiss we submit the solut
4,refer 1 2 3
0,introduct home credit default risk competit thi notebook is intend for those who are new to machin learn competit or want a gentl introduct to the problem i purpos avoid jump into complic model or join togeth lot of data in order to show the basic of how to get start in machin learn ani comment or suggest are much appreci in thi notebook we will take an initi look at the home credit default risk machin learn competit current host on kaggl the object of thi competit is to use histor loan applic data to predict whether or not an applic will be abl to repay a loan thi is a standard supervis classif task supervis the label are includ in the train data and the goal is to train a model to learn to predict the label from the featur classif the label is a binari variabl 0 will repay loan on time 1 will have difficulti repay loan data the data is provid by home credit a servic dedic to provid line of credit loan to the unbank popul predict whether or not a client will repay a loan or have difficulti is a critic busi need and home credit is host thi competit on kaggl to see what sort of model the machin learn commun can develop to help them in thi task there are 7 differ sourc of data applic train applic test the main train and test data with inform about each loan applic at home credit everi loan ha it own row and is identifi by the featur sk id curr the train applic data come with the target indic 0 the loan wa repaid or 1 the loan wa not repaid bureau data concern client s previou credit from other financi institut each previou credit ha it own row in bureau but one loan in the applic data can have multipl previou credit bureau balanc monthli data about the previou credit in bureau each row is one month of a previou credit and a singl previou credit can have multipl row one for each month of the credit length previou applic previou applic for loan at home credit of client who have loan in the applic data each current loan in the applic data can have multipl previou loan each previou applic ha one row and is identifi by the featur sk id prev po cash balanc monthli data about previou point of sale or cash loan client have had with home credit each row is one month of a previou point of sale or cash loan and a singl previou loan can have mani row credit card balanc monthli data about previou credit card client have had with home credit each row is one month of a credit card balanc and a singl credit card can have mani row instal payment payment histori for previou loan at home credit there is one row for everi made payment and one row for everi miss payment thi diagram show how all of the data is relat imag moreov we are provid with the definit of all the column in homecredit column descript csv and an exampl of the expect submiss file in thi notebook we will stick to use onli the main applic train and test data although if we want to have ani hope of serious compet we need to use all the data for now we will stick to one file which should be more manag thi will let u establish a baselin that we can then improv upon with these project it s best to build up an understand of the problem a littl at a time rather than dive all the way in and get complet lost metric roc auc onc we have a grasp of the data read through the column descript help immens we need to understand the metric by which our submiss is judg in thi case it is a common classif metric known a the receiv oper characterist area under the curv roc auc also sometim call auroc the roc auc may sound intimid but it is rel straightforward onc you can get your head around the two individu concept the reciev oper characterist roc curv graph the true posit rate versu the fals posit rate imag a singl line on the graph indic the curv for a singl model and movement along a line indic chang the threshold use for classifi a posit instanc the threshold start at 0 in the upper right to and goe to 1 in the lower left a curv that is to the left and abov anoth curv indic a better model for exampl the blue model is better than the red model which is better than the black diagon line which indic a naiv random guess model the area under the curv auc explain itself by it name it is simpli the area under the roc curv thi is the integr of the curv thi metric is between 0 and 1 with a better model score higher a model that simpli guess at random will have an roc auc of 0 5 when we measur a classifi accord to the roc auc we do not gener 0 or 1 predict but rather a probabl between 0 and 1 thi may be confus becaus we usual like to think in term of accuraci but when we get into problem with inbalanc class we will see thi is the case accuraci is not the best metric for exampl if i want to build a model that could detect terrorist with 99 9999 accuraci i would simpli make a model that predict everi singl person wa not a terrorist clearli thi would not be effect the recal would be zero and we use more advanc metric such a roc auc or the f1 score to more accur reflect the perform of a classifi a model with a high roc auc will also have a high accuraci but the roc auc is a better represent of model perform not that we know the background of the data we are use and the metric to maxim let s get into explor the data in thi notebook a mention previous we will stick to the main data sourc and simpl model which we can build upon in futur work follow up notebook for those look to keep work on thi problem i have a seri of follow up notebook manual featur engin part one manual featur engin part two introduct to autom featur engin advanc autom featur engin featur select intro to model tune grid and random search autom model tune model tune result i ll add more notebook a i finish them thank for all the comment
1,import we are use a typic data scienc stack numpi panda sklearn matplotlib
0,read in data first we can list all the avail data file there are a total of 9 file 1 main file for train with target 1 main file for test without the target 1 exampl submiss file and 6 other file contain addit inform about each loan
0,the train data ha 307511 observ each one a separ loan and 122 featur variabl includ the target the label we want to predict
0,the test set is consider smaller and lack a target column
0,exploratori data analysi exploratori data analysi eda is an open end process where we calcul statist and make figur to find trend anomali pattern or relationship within the data the goal of eda is to learn what our data can tell u it gener start out with a high level overview then narrow in to specif area a we find intrigu area of the data the find may be interest in their own right or they can be use to inform our model choic such a by help u decid which featur to use examin the distribut of the target column the target is what we are ask to predict either a 0 for the loan wa repaid on time or a 1 indic the client had payment difficulti we can first examin the number of loan fall into each categori
0,from thi inform we see thi is an imbalanc class problem there are far more loan that were repaid on time than loan that were not repaid onc we get into more sophist machin learn model we can weight the class by their represent in the data to reflect thi imbal examin miss valu next we can look at the number and percentag of miss valu in each column
0,when it come time to build our machin learn model we will have to fill in these miss valu known a imput in later work we will use model such a xgboost that can handl miss valu with no need for imput anoth option would be to drop column with a high percentag of miss valu although it is imposs to know ahead of time if these column will be help to our model therefor we will keep all of the column for now column type let s look at the number of column of each data type int64 and float64 are numer variabl which can be either discret or continu object column contain string and are categor featur
0,let s now look at the number of uniqu entri in each of the object categor column
0,most of the categor variabl have a rel small number of uniqu entri we will need to find a way to deal with these categor variabl encod categor variabl befor we go ani further we need to deal with peski categor variabl a machin learn model unfortun cannot deal with categor variabl except for some model such a lightgbm therefor we have to find a way to encod repres these variabl a number befor hand them off to the model there are two main way to carri out thi process label encod assign each uniqu categori in a categor variabl with an integ no new column are creat an exampl is shown below imag one hot encod creat a new column for each uniqu categori in a categor variabl each observ reciev a 1 in the column for it correspond categori and a 0 in all other new column imag the problem with label encod is that it give the categori an arbitrari order the valu assign to each of the categori is random and doe not reflect ani inher aspect of the categori in the exampl abov programm reciev a 4 and data scientist a 1 but if we did the same process again the label could be revers or complet differ the actual assign of the integ is arbitrari therefor when we perform label encod the model might use the rel valu of the featur for exampl programm 4 and data scientist 1 to assign weight which is not what we want if we onli have two uniqu valu for a categor variabl such a male femal then label encod is fine but for more than 2 uniqu categori one hot encod is the safe option there is some debat about the rel merit of these approach and some model can deal with label encod categor variabl with no issu here is a good stack overflow discus i think and thi is just a person opinion for categor variabl with mani class one hot encod is the safest approach becaus it doe not impos arbitrari valu to categori the onli downsid to one hot encod is that the number of featur dimens of the data can explod with categor variabl with mani categori to deal with thi we can perform one hot encod follow by pca or other dimension reduct method to reduc the number of dimens while still tri to preserv inform in thi notebook we will use label encod for ani categor variabl with onli 2 categori and one hot encod for ani categor variabl with more than 2 categori thi process may need to chang a we get further into the project but for now we will see where thi get u we will also not use ani dimension reduct in thi notebook but will explor in futur iter label encod and one hot encod let s implement the polici describ abov for ani categor variabl dtype object with 2 uniqu categori we will use label encod and for ani categor variabl with more than 2 uniqu categori we will use one hot encod for label encod we use the scikit learn labelencod and for one hot encod the panda get dummi df function
0,align train and test data there need to be the same featur column in both the train and test data one hot encod ha creat more column in the train data becaus there were some categor variabl with categori not repres in the test data to remov the column in the train data that are not in the test data we need to align the datafram first we extract the target column from the train data becaus thi is not in the test data but we need to keep thi inform when we do the align we must make sure to set axi 1 to align the datafram base on the column and not on the row
0,the train and test dataset now have the same featur which is requir for machin learn the number of featur ha grown significantli due to one hot encod at some point we probabl will want to tri dimension reduct remov featur that are not relev to reduc the size of the dataset back to exploratori data analysi anomali one problem we alway want to be on the lookout for when do eda is anomali within the data these may be due to mi type number error in measur equip or they could be valid but extrem measur one way to support anomali quantit is by look at the statist of a column use the describ method the number in the day birth column are neg becaus they are record rel to the current loan applic to see these stat in year we can mutlipl by 1 and divid by the number of day in a year
0,those age look reason there are no outlier for the age on either the high or low end how about the day of employ
0,that doesn t look right the maximum valu besid be posit is about 1000 year
0,just out of curious let s subset the anomal client and see if they tend to have higher or low rate of default than the rest of the client
0,well that is extrem interest it turn out that the anomali have a lower rate of default handl the anomali depend on the exact situat with no set rule one of the safest approach is just to set the anomali to a miss valu and then have them fill in use imput befor machin learn in thi case sinc all the anomali have the exact same valu we want to fill them in with the same valu in case all of these loan share someth in common the anomal valu seem to have some import so we want to tell the machin learn model if we did in fact fill in these valu a a solut we will fill in the anomal valu with not a number np nan and then creat a new boolean column indic whether or not the valu wa anomal
0,the distribut look to be much more in line with what we would expect and we also have creat a new column to tell the model that these valu were origin anomal becuas we will have to fill in the nan with some valu probabl the median of the column the other column with day in the datafram look to be about what we expect with no obviou outlier a an extrem import note anyth we do to the train data we also have to do to the test data let s make sure to creat the new column and fill in the exist column with np nan in the test data
0,correl now that we have dealt with the categor variabl and the outlier let s continu with the eda one way to tri and understand the data is by look for correl between the featur and the target we can calcul the pearson correl coeffici between everi variabl and the target use the corr datafram method the correl coeffici is not the greatest method to repres relev of a featur but it doe give u an idea of possibl relationship within the data some gener interpret of the absolut valu of the correl coeffic are 00 19 “veri weak” 20 39 “weak” 40 59 “moderate” 60 79 “strong” 80 1 0 “veri strong”
0,let s take a look at some of more signific correl the day birth is the most posit correl except for target becaus the correl of a variabl with itself is alway 1 look at the document day birth is the age in day of the client at the time of the loan in neg day for whatev reason the correl is posit but the valu of thi featur is actual neg mean that a the client get older they are le like to default on their loan ie the target 0 that s a littl confus so we will take the absolut valu of the featur and then the correl will be neg effect of age on repay
0,a the client get older there is a neg linear relationship with the target mean that a client get older they tend to repay their loan on time more often let s start look at thi variabl first we can make a histogram of the age we will put the x axi in year to make the plot a littl more understand
0,by itself the distribut of age doe not tell u much other than that there are no outlier a all the age are reason to visual the effect of the age on the target we will next make a kernel densiti estim plot kde color by the valu of the target a kernel densiti estim plot show the distribut of a singl variabl and can be thought of a a smooth histogram it is creat by comput a kernel usual a gaussian at each data point and then averag all the individu kernel to develop a singl smooth curv we will use the seaborn kdeplot for thi graph
0,the target 1 curv skew toward the younger end of the rang although thi is not a signific correl 0 07 correl coeffici thi variabl is like go to be use in a machin learn model becaus it doe affect the target let s look at thi relationship in anoth way averag failur to repay loan by age bracket to make thi graph first we cut the age categori into bin of 5 year each then for each bin we calcul the averag valu of the target which tell u the ratio of loan that were not repaid in each age categori
0,there is a clear trend younger applic are more like to not repay the loan the rate of failur to repay is abov 10 for the youngest three age group and beolow 5 for the oldest age group thi is inform that could be directli use by the bank becaus younger client are le like to repay the loan mayb they should be provid with more guidanc or financi plan tip thi doe not mean the bank should discrimin against younger client but it would be smart to take precautionari measur to help younger client pay on time exterior sourc the 3 variabl with the strongest neg correl with the target are ext sourc 1 ext sourc 2 and ext sourc 3 accord to the document these featur repres a normal score from extern data sourc i m not sure what thi exactli mean but it may be a cumul sort of credit rate made use numer sourc of data let s take a look at these variabl first we can show the correl of the ext sourc featur with the target and with each other
0,all three ext sourc featureshav neg correl with the target indic that a the valu of the ext sourc increas the client is more like to repay the loan we can also see that day birth is posit correl with ext sourc 1 indic that mayb one of the factor in thi score is the client age next we can look at the distribut of each of these featur color by the valu of the target thi will let u visual the effect of thi variabl on the target
0,ext sourc 3 display the greatest differ between the valu of the target we can clearli see that thi featur ha some relationship to the likelihood of an applic to repay a loan the relationship is not veri strong in fact they are all consid veri weak but these variabl will still be use for a machin learn model to predict whether or not an applic will repay a loan on time pair plot a a final exploratori plot we can make a pair plot of the ext sourc variabl and the day birth variabl the pair plot is a great explor tool becaus it let u see relationship between multipl pair of variabl a well a distribut of singl variabl here we are use the seaborn visual librari and the pairgrid function to creat a pair plot with scatterplot on the upper triangl histogram on the diagon and 2d kernel densiti plot and correl coeffici on the lower triangl if you don t understand thi code that s all right plot in python can be overli complex and for anyth beyond the simplest graph i usual find an exist implement and adapt the code don t repeat yourself
0,in thi plot the red indic loan that were not repaid and the blue are loan that are paid we can see the differ relationship within the data there doe appear to be a moder posit linear relationship between the ext sourc 1 and the day birth or equival year birth indic that thi featur may take into account the age of the client
0,in thi plot the red indic loan that were not repaid and the blue are loan that are paid we can see the differ relationship within the data there doe appear to be a moder posit linear relationship between the ext sourc 1 and the day birth or equival year birth indic that thi featur may take into account the age of the client featur engin kaggl competit are won by featur engin those win are those who can creat the most use featur out of the data thi is true for the most part a the win model at least for structur data all tend to be variant on gradient boost thi repres one of the pattern in machin learn featur engin ha a greater return on invest than model build and hyperparamet tune thi is a great articl on the subject a andrew ng is fond of say appli machin learn is basic featur engin while choos the right model and optim set are import the model can onli learn from the data it is given make sure thi data is a relev to the task a possibl is the job of the data scientist and mayb some autom tool to help u out featur engin refer to a geneal process and can involv both featur construct ad new featur from the exist data and featur select choos onli the most import featur or other method of dimension reduct there are mani techniqu we can use to both creat featur and select featur we will do a lot of featur engin when we start use the other data sourc but in thi notebook we will tri onli two simpl featur construct method polynomi featur domain knowledg featur polynomi featur one simpl featur construct method is call polynomi featur in thi method we make featur that are power of exist featur a well a interact term between exist featur for exampl we can creat variabl ext sourc 1 2 and ext sourc 2 2 and also variabl such a ext sourc 1 x ext sourc 2 ext sourc 1 x ext sourc 2 2 ext sourc 1 2 x ext sourc 2 2 and so on these featur that are a combin of multipl individu variabl are call interact term becaus they captur the interact between variabl in other word while two variabl by themselv may not have a strong influenc on the target combin them togeth into a singl interact variabl might show a relationship with the target interact term are commonli use in statist model to captur the effect of multipl variabl but i do not see them use a often in machin learn nonetheless we can tri out a few to see if they might help our model to predict whether or not a client will repay a loan jake vanderpla write about polynomi featur in hi excel book python for data scienc for those who want more inform in the follow code we creat polynomi featur use the ext sourc variabl and the day birth variabl scikit learn ha a use class call polynomialfeatur that creat the polynomi and the interact term up to a specifi degre we can use a degre of 3 to see the result when we are creat polynomi featur we want to avoid use too high of a degre both becaus the number of featur scale exponenti with the degre and becaus we can run into problem with overfit
0,thi creat a consider number of new featur to get the name we have to use the polynomi featur get featur name method
0,there are 35 featur with individu featur rais to power up to degre 3 and interact term now we can see whether ani of these new featur are correl with the target
0,sever of the new variabl have a greater in term of absolut magnitud correl with the target than the origin featur when we build machin learn model we can tri with and without these featur to determin if they actual help the model learn we will add these featur to a copi of the train and test data and then evalu model with and without the featur mani time in machin learn the onli way to know if an approach will work is to tri it out
0,domain knowledg featur mayb it s not entir correct to call thi domain knowledg becaus i m not a credit expert but perhap we could call thi attempt at appli limit financi knowledg in thi frame of mind we can make a coupl featur that attempt to captur what we think may be import for tell whether a client will default on a loan here i m go to use five featur that were inspir by thi script by aguiar credit incom percent the percentag of the credit amount rel to a client s incom annuiti incom percent the percentag of the loan annuiti rel to a client s incom credit term the length of the payment in month sinc the annuiti is the monthli amount due day employ percent the percentag of the day employ rel to the client s age again thank to aguiar and hi great script for explor these featur
0,visual new variabl we should explor these domain knowledg variabl visual in a graph for all of these we will make the same kde plot color by the valu of the target
0,it s hard to say ahead of time if these new featur will be use the onli way to tell for sure is to tri them out baselin for a naiv baselin we could guess the same valu for all exampl on the test set we are ask to predict the probabl of not repay the loan so if we are entir unsur we would guess 0 5 for all observ on the test set thi will get u a reciev oper characterist area under the curv auc roc of 0 5 in the competit random guess on a classif task will score a 0 5 sinc we alreadi know what score we are go to get we don t realli need to make a naiv baselin guess let s use a slightli more sophist model for our actual baselin logist regress logist regress implement here i will focu on implement the model rather than explain the detail but for those who want to learn more about the theori of machin learn algorithm i recommend both an introduct to statist learn and hand on machin learn with scikit learn and tensorflow both of these book present the theori and also the code need to make the model in r and python respect they both teach with the mindset that the best way to learn is by do and they are veri effect to get a baselin we will use all of the featur after encod the categor variabl we will preprocess the data by fill in the miss valu imput and normal the rang of the featur featur scale the follow code perform both of these preprocess step
0,we will use logisticregress from scikit learn for our first model the onli chang we will make from the default model set is to lower the regular paramet c which control the amount of overfit a lower valu should decreas overfit thi will get u slightli better result than the default logisticregress but it still will set a low bar for ani futur model here we use the familiar scikit learn model syntax we first creat the model then we train the model use fit and then we make predict on the test data use predict proba rememb that we want probabl and not a 0 or 1
0,now that the model ha been train we can use it to make predict we want to predict the probabl of not pay a loan so we use the model predict proba method thi return an m x 2 array where m is the number of observ the first column is the probabl of the target be 0 and the second column is the probabl of the target be 1 so for a singl row the two column must sum to 1 we want the probabl the loan is not repaid so we will select the second column the follow code make the predict and select the correct column
0,the predict must be in the format shown in the sampl submiss csv file where there are onli two column sk id curr and target we will creat a datafram in thi format from the test set and the predict call submit
0,the predict repres a probabl between 0 and 1 that the loan will not be repaid if we were use these predict to classifi applic we could set a probabl threshold for determin that a loan is riski
0,the submiss ha now been save to the virtual environ in which our notebook is run to access the submiss at the end of the notebook we will hit the blue commit run button at the upper right of the kernel thi run the entir notebook and then let u download ani file that are creat dure the run onc we run the notebook the file creat are avail in the version tab under the output sub tab from here the submiss file can be submit to the competit or download sinc there are sever model in thi notebook there will be multipl output file the logist regress baselin should score around 0 671 when submit improv model random forest to tri and beat the poor perform of our baselin we can updat the algorithm let s tri use a random forest on the same train data to see how that affect perform the random forest is a much more power model especi when we use hundr of tree we will use 100 tree in the random forest
0,these predict will also be avail when we run the entir notebook thi model should score around 0 678 when submit make predict use engin featur the onli way to see if the polynomi featur and domain knowledg improv the model is to train a test a model on these featur we can then compar the submiss perform to that for the model without these featur to gaug the effect of our featur engin
0,thi model score 0 678 when submit to the competit exactli the same a that without the engin featur given these result it doe not appear that our featur construct help in thi case test domain featur now we can test the domain featur we made by hand
0,thi score 0 679 when submit which probabl show that the engin featur do not help in thi model howev they do help in the gradient boost model at the end of the notebook in later notebook we will do more featur engin by use the inform from the other data sourc from experi thi will definit help our model model interpret featur import a a simpl method to see which variabl are the most relev we can look at the featur import of the random forest given the correl we saw in the exploratori data analysi we should expect that the most import featur are the ext sourc and the day birth we may use these featur import a a method of dimension reduct in futur work
0,a expect the most import featur are those deal with ext sourc and day birth we see that there are onli a hand of featur with a signific import to the model which suggest we may be abl to drop mani of the featur without a decreas in perform and we may even see an increas in perform featur import are not the most sophist method to interpret a model or perform dimension reduct but they let u start to understand what factor our model take into account when it make predict
0,we see that all four of our hand engin featur made it into the top 15 most import thi should give u confid that our domain knowledg wa at least partial on track conclus in thi notebook we saw how to get start with a kaggl machin learn competit we first made sure to understand the data our task and the metric by which our submiss will be judg then we perform a fairli simpl eda to tri and identifi relationship trend or anomali that may help our model along the way we perform necessari preprocess step such a encod categor variabl imput miss valu and scale featur to a rang then we construct new featur out of the exist data to see if do so could help our model onc the data explor data prepar and featur engin wa complet we implement a baselin model upon which we hope to improv then we built a second slightli more complic model to beat our first score we also carri out an experi to determin the effect of ad the engin variabl we follow the gener outlin of a machin learn project 1 understand the problem and the data 2 data clean and format thi wa mostli done for u 3 exploratori data analysi 4 baselin model 5 improv model 6 model interpret just a littl machin learn competit do differ slightli from typic data scienc problem in that we are concern onli with achiev the best perform on a singl metric and do not care about the interpret howev by attempt to understand how our model make decis we can tri to improv them or examin the mistak in order to correct the error in futur notebook we will look at incorpor more sourc of data build more complex model by follow the code of other and improv our score i hope thi notebook wa abl to get you up and run in thi machin learn competit and that you are now readi to go out on your own with help from the commun and start work on some great problem run the notebook now that we are at the end of the notebook you can hit the blue commit run button to execut all the code at onc after the run is complet thi should take about 10 minut you can then access the file that were creat by go to the version tab and then the output sub tab the submiss file can be directli submit to the competit from thi tab or they can be download to a local machin and save the final part is to share the share the notebook go to the set tab and chang the visibl to public thi allow the entir world to see your work follow up notebook for those look to keep work on thi problem i have a seri of follow up notebook manual featur engin part one manual featur engin part two introduct to autom featur engin advanc autom featur engin featur select intro to model tune grid and random search a alway i welcom feedback and construct critic i write for toward data scienc at and can be reach on twitter at will just for fun light gradient boost machin now if you want thi part is entir option we can step off the deep end and use a real machin learn model the gradient boost machin use the lightgbm librari the gradient boost machin is current the lead model for learn on structur dataset especi on kaggl and we will probabl need some form of thi model to do well in the competit don t worri even if thi code look intimid it s just a seri of small step that build up to a complet model i ad thi code just to show what may be in store for thi project and becaus it get u a slightli better score on the leaderboard in futur notebook we will see how to work with more advanc model which mostli mean adapt exist code to make it work better featur engin and featur select see you in the next notebook
0,thi submiss should score about 0 735 on the leaderboard we will certainli best that in futur work
0,again we see tha some of our featur made it into the most import go forward we will need to think about whatoth domain knowledg featur may be use for thi problem or we should consult someon who know more about the financi industri
0,thi model score about 0 754 when submit to the public leaderboard indic that the domain featur do improv the perform featur engin is go to be a critic part of thi competit a it is for all machin learn problem
