{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generate random data"
      ],
      "metadata": {
        "id": "w4t0oILMZA1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random numeric data"
      ],
      "metadata": {
        "id": "pWHkF5EaZblM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(90)\n",
        "numeric_data = np.random.randn(50, 2)"
      ],
      "metadata": {
        "id": "-6d1mPHXY-xZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random text data"
      ],
      "metadata": {
        "id": "-Vr4TcDyZddR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "text_data = pd.DataFrame({\n",
        "    \"text_col\": [\n",
        "        \"This TEXT needs \\t\\t\\tsome cleaning!!!...\", \n",
        "        \"This text too!!...       \", \n",
        "        \"Yes, you got it right!\\n This one too\\n\"\n",
        "    ]\n",
        "})"
      ],
      "metadata": {
        "id": "ZO0k06zAZf3Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of KMeans Clustering"
      ],
      "metadata": {
        "id": "0QPSqU8HLwaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Generate example data\n",
        "np.random.seed(90)\n",
        "original_data = np.random.randn(50, 2)\n",
        "\n",
        "# Kmeans model\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "\n",
        "# Fit the moodel with randomed data\n",
        "kmeans.fit(original_data)\n",
        "\n",
        "# Predict cluster assignment for original data\n",
        "cluster_assignment = kmeans.predict(original_data)\n",
        "\n",
        "# map cluster to original data\n",
        "mapped_data = np.column_stack((original_data, cluster_assignment))\n",
        "# mapped_data = pd.DataFrame({'x': original_data[0], 'y': original_data[1], 'cluster': cluster_assignment})\n",
        "\n",
        "print(type(original_data[0]))\n",
        "# print(mapped_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5SfKakYLzNu",
        "outputId": "bcdb8f84-8384-4df6-a53c-7178fc1ac44b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of Text Vectorizer using Bag-of-words approach"
      ],
      "metadata": {
        "id": "l5HrWi4GL2QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing text using Bag-of-word method with CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bow_representation = vectorizer.fit_transform(text_data['text_col'])\n",
        "# bow_representation\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(bow_representation.toarray())\n",
        "print(type(bow_representation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnqoo3AKL0Gx",
        "outputId": "2c43b606-7770-4ab0-9292-448aef24fdf5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cleaning' 'got' 'it' 'needs' 'one' 'right' 'some' 'text' 'this' 'too'\n",
            " 'yes' 'you']\n",
            "[[1 0 0 1 0 0 1 1 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 1 1 0 0]\n",
            " [0 1 1 0 1 1 0 0 1 1 1 1]]\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latent Dirichlet Allocation Example"
      ],
      "metadata": {
        "id": "lP80f_v8L_B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Latent Dirichlet Allocation example\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tfidf = TfidfVectorizer(lowercase=True,\n",
        "                        stop_words='english',\n",
        "                        tokenizer = tokenizer.tokenize)\n",
        "\n",
        "train_data = tfidf.fit_transform(text_data['text_col'])"
      ],
      "metadata": {
        "id": "l-U3NmeZL6bu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LatentDirichletAllocation(n_components=5)\n",
        "lda_matrix = lda.fit_transform(train_data)\n",
        "\n",
        "# Get Components \n",
        "lda_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K1mWKTWMC1k",
        "outputId": "cc92a9fd-ce3d-4e85-a964-5d042852248d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.07365551, 0.07358351, 0.07662975, 0.70247572, 0.07365551],\n",
              "       [0.10005257, 0.10001601, 0.59893558, 0.10094327, 0.10005257],\n",
              "       [0.07330893, 0.70689708, 0.07324889, 0.07323617, 0.07330893]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EdqDC0p7Z4Lt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}