{
	"grandmaster": {
		"correct_pairs_summarize": { "ml": 294, "es": 2512, "es-processed": 2132 },
		"incorrect_pairs_items": [
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nimport os\nimport gc\nimport time\nimport math\nimport datetime\nfrom math import log, floor\nfrom sklearn.neighbors import KDTree\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.utils import shuffle\nfrom tqdm.notebook import tqdm as tqdm\n\nimport seaborn as sns\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport pywt\nfrom statsmodels.robust import mad\n\nimport scipy\nimport statsmodels\nfrom scipy import signal\nimport statsmodels.api as sm\nfrom fbprophet import Prophet\nfrom scipy.signal import butter, deconvolve\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nimport os\nimport gc\nimport time\nimport math\nimport datetime\nfrom math import log, floor\nfrom sklearn.neighbors import KDTree\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.utils import shuffle\nfrom tqdm.notebook import tqdm as tqdm\n\nimport seaborn as sns\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport pywt\nfrom statsmodels.robust import mad\n\nimport scipy\nimport statsmodels\nfrom scipy import signal\nimport statsmodels.api as sm\nfrom fbprophet import Prophet\nfrom scipy.signal import butter, deconvolve\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nids = sorted(list(set(sales_train_val['id'])))\nd_cols = [c for c in sales_train_val.columns if 'd_' in c]\nx_1 = sales_train_val.loc[sales_train_val['id'] == ids[2]].set_index('id')[d_cols].values[0]\nx_2 = sales_train_val.loc[sales_train_val['id'] == ids[1]].set_index('id')[d_cols].values[0]\nx_3 = sales_train_val.loc[sales_train_val['id'] == ids[17]].set_index('id')[d_cols].values[0]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_1)), y=x_1, showlegend=False,\n                    mode='lines', name=\"First sample\",\n                         marker=dict(color=\"mediumseagreen\")),\n             row=1, col=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_2)), y=x_2, showlegend=False,\n                    mode='lines', name=\"Second sample\",\n                         marker=dict(color=\"violet\")),\n             row=2, col=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_3)), y=x_3, showlegend=False,\n                    mode='lines', name=\"Third sample\",\n                         marker=dict(color=\"dodgerblue\")),\n             row=3, col=1)\n\nfig.update_layout(height=1200, width=800, title_text=\"Sample sales\")\nfig.show()",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nids = sorted(list(set(sales_train_val['id'])))\nd_cols = [c for c in sales_train_val.columns if 'd_' in c]\nx_1 = sales_train_val.loc[sales_train_val['id'] == ids[2]].set_index('id')[d_cols].values[0]\nx_2 = sales_train_val.loc[sales_train_val['id'] == ids[1]].set_index('id')[d_cols].values[0]\nx_3 = sales_train_val.loc[sales_train_val['id'] == ids[17]].set_index('id')[d_cols].values[0]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_1)), y=x_1, showlegend=False,\n                    mode='lines', name=\"First sample\",\n                         marker=dict(color=\"mediumseagreen\")),\n             row=1, col=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_2)), y=x_2, showlegend=False,\n                    mode='lines', name=\"Second sample\",\n                         marker=dict(color=\"violet\")),\n             row=2, col=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_3)), y=x_3, showlegend=False,\n                    mode='lines', name=\"Third sample\",\n                         marker=dict(color=\"dodgerblue\")),\n             row=3, col=1)\n\nfig.update_layout(height=1200, width=800, title_text=\"Sample sales\")\nfig.show()"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nids = sorted(list(set(sales_train_val['id'])))\nd_cols = [c for c in sales_train_val.columns if 'd_' in c]\nx_1 = sales_train_val.loc[sales_train_val['id'] == ids[0]].set_index('id')[d_cols].values[0][:90]\nx_2 = sales_train_val.loc[sales_train_val['id'] == ids[4]].set_index('id')[d_cols].values[0][1300:1400]\nx_3 = sales_train_val.loc[sales_train_val['id'] == ids[65]].set_index('id')[d_cols].values[0][350:450]\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_1)), y=x_1, showlegend=False,\n                    mode='lines+markers', name=\"First sample\",\n                         marker=dict(color=\"mediumseagreen\")),\n             row=1, col=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_2)), y=x_2, showlegend=False,\n                    mode='lines+markers', name=\"Second sample\",\n                         marker=dict(color=\"violet\")),\n             row=2, col=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_3)), y=x_3, showlegend=False,\n                    mode='lines+markers', name=\"Third sample\",\n                         marker=dict(color=\"dodgerblue\")),\n             row=3, col=1)\n\nfig.update_layout(height=1200, width=800, title_text=\"Sample sales snippets\")\nfig.show()",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nids = sorted(list(set(sales_train_val['id'])))\nd_cols = [c for c in sales_train_val.columns if 'd_' in c]\nx_1 = sales_train_val.loc[sales_train_val['id'] == ids[0]].set_index('id')[d_cols].values[0][:90]\nx_2 = sales_train_val.loc[sales_train_val['id'] == ids[4]].set_index('id')[d_cols].values[0][1300:1400]\nx_3 = sales_train_val.loc[sales_train_val['id'] == ids[65]].set_index('id')[d_cols].values[0][350:450]\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_1)), y=x_1, showlegend=False,\n                    mode='lines+markers', name=\"First sample\",\n                         marker=dict(color=\"mediumseagreen\")),\n             row=1, col=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_2)), y=x_2, showlegend=False,\n                    mode='lines+markers', name=\"Second sample\",\n                         marker=dict(color=\"violet\")),\n             row=2, col=1)\n\nfig.add_trace(go.Scatter(x=np.arange(len(x_3)), y=x_3, showlegend=False,\n                    mode='lines+markers', name=\"Third sample\",\n                         marker=dict(color=\"dodgerblue\")),\n             row=3, col=1)\n\nfig.update_layout(height=1200, width=800, title_text=\"Sample sales snippets\")\nfig.show()"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\ndef maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\ndef denoise_signal(x, wavelet='db4', level=1):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * maddest(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    return pywt.waverec(coeff, wavelet, mode='per')\ny_w1 = denoise_signal(x_1)\ny_w2 = denoise_signal(x_2)\ny_w3 = denoise_signal(x_3)\n\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_1)), mode='lines+markers', y=x_1, marker=dict(color=\"mediumaquamarine\"), showlegend=False,\n               name=\"Original signal\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_1)), y=y_w1, mode='lines', marker=dict(color=\"darkgreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_2)), mode='lines+markers', y=x_2, marker=dict(color=\"thistle\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_2)), y=y_w2, mode='lines', marker=dict(color=\"purple\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_3)), mode='lines+markers', y=x_3, marker=dict(color=\"lightskyblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_3)), y=y_w3, mode='lines', marker=dict(color=\"navy\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Original (pale) vs. Denoised (dark) sales\")\nfig.show()",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\ndef maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\ndef denoise_signal(x, wavelet='db4', level=1):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * maddest(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    return pywt.waverec(coeff, wavelet, mode='per')\ny_w1 = denoise_signal(x_1)\ny_w2 = denoise_signal(x_2)\ny_w3 = denoise_signal(x_3)\n\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_1)), mode='lines+markers', y=x_1, marker=dict(color=\"mediumaquamarine\"), showlegend=False,\n               name=\"Original signal\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_1)), y=y_w1, mode='lines', marker=dict(color=\"darkgreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_2)), mode='lines+markers', y=x_2, marker=dict(color=\"thistle\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_2)), y=y_w2, mode='lines', marker=dict(color=\"purple\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_3)), mode='lines+markers', y=x_3, marker=dict(color=\"lightskyblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_3)), y=y_w3, mode='lines', marker=dict(color=\"navy\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Original (pale) vs. Denoised (dark) sales\")\nfig.show()"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nfig, ax = plt.subplots(nrows=3, ncols=2, figsize=(30, 20))\n\nax[0, 0].plot(x_1, color='seagreen', marker='o') \nax[0, 0].set_title('Original Sales', fontsize=24)\nax[0, 1].plot(y_w1, color='red', marker='.') \nax[0, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nax[1, 0].plot(x_2, color='seagreen', marker='o') \nax[1, 0].set_title('Original Sales', fontsize=24)\nax[1, 1].plot(y_w2, color='red', marker='.') \nax[1, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nax[2, 0].plot(x_3, color='seagreen', marker='o') \nax[2, 0].set_title('Original Sales', fontsize=24)\nax[2, 1].plot(y_w3, color='red', marker='.') \nax[2, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nplt.show()",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nfig, ax = plt.subplots(nrows=3, ncols=2, figsize=(30, 20))\n\nax[0, 0].plot(x_1, color='seagreen', marker='o') \nax[0, 0].set_title('Original Sales', fontsize=24)\nax[0, 1].plot(y_w1, color='red', marker='.') \nax[0, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nax[1, 0].plot(x_2, color='seagreen', marker='o') \nax[1, 0].set_title('Original Sales', fontsize=24)\nax[1, 1].plot(y_w2, color='red', marker='.') \nax[1, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nax[2, 0].plot(x_3, color='seagreen', marker='o') \nax[2, 0].set_title('Original Sales', fontsize=24)\nax[2, 1].plot(y_w3, color='red', marker='.') \nax[2, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nplt.show()"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\ndef average_smoothing(signal, kernel_size=3, stride=1):\n    sample = []\n    start = 0\n    end = kernel_size\n    while end <= len(signal):\n        start = start + stride\n        end = end + stride\n        sample.extend(np.ones(end - start)*np.mean(signal[start:end]))\n    return np.array(sample)\ny_a1 = average_smoothing(x_1)\ny_a2 = average_smoothing(x_2)\ny_a3 = average_smoothing(x_3)\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_1)), mode='lines+markers', y=x_1, marker=dict(color=\"lightskyblue\"), showlegend=False,\n               name=\"Original sales\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_1)), y=y_a1, mode='lines', marker=dict(color=\"navy\"), showlegend=False,\n               name=\"Denoised sales\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_2)), mode='lines+markers', y=x_2, marker=dict(color=\"thistle\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_2)), y=y_a2, mode='lines', marker=dict(color=\"indigo\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_3)), mode='lines+markers', y=x_3, marker=dict(color=\"mediumaquamarine\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_3)), y=y_a3, mode='lines', marker=dict(color=\"darkgreen\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Original (pale) vs. Denoised (dark) signals\")\nfig.show()",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\ndef average_smoothing(signal, kernel_size=3, stride=1):\n    sample = []\n    start = 0\n    end = kernel_size\n    while end <= len(signal):\n        start = start + stride\n        end = end + stride\n        sample.extend(np.ones(end - start)*np.mean(signal[start:end]))\n    return np.array(sample)\ny_a1 = average_smoothing(x_1)\ny_a2 = average_smoothing(x_2)\ny_a3 = average_smoothing(x_3)\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_1)), mode='lines+markers', y=x_1, marker=dict(color=\"lightskyblue\"), showlegend=False,\n               name=\"Original sales\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_1)), y=y_a1, mode='lines', marker=dict(color=\"navy\"), showlegend=False,\n               name=\"Denoised sales\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_2)), mode='lines+markers', y=x_2, marker=dict(color=\"thistle\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_2)), y=y_a2, mode='lines', marker=dict(color=\"indigo\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_3)), mode='lines+markers', y=x_3, marker=dict(color=\"mediumaquamarine\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(len(x_3)), y=y_a3, mode='lines', marker=dict(color=\"darkgreen\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Original (pale) vs. Denoised (dark) signals\")\nfig.show()"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nfig, ax = plt.subplots(nrows=3, ncols=2, figsize=(30, 20))\n\nax[0, 0].plot(x_1, color='seagreen', marker='o') \nax[0, 0].set_title('Original Sales', fontsize=24)\nax[0, 1].plot(y_a1, color='red', marker='.') \nax[0, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nax[1, 0].plot(x_2, color='seagreen', marker='o') \nax[1, 0].set_title('Original Sales', fontsize=24)\nax[1, 1].plot(y_a2, color='red', marker='.') \nax[1, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nax[2, 0].plot(x_3, color='seagreen', marker='o') \nax[2, 0].set_title('Original Sales', fontsize=24)\nax[2, 1].plot(y_a3, color='red', marker='.') \nax[2, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nplt.show()",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nfig, ax = plt.subplots(nrows=3, ncols=2, figsize=(30, 20))\n\nax[0, 0].plot(x_1, color='seagreen', marker='o') \nax[0, 0].set_title('Original Sales', fontsize=24)\nax[0, 1].plot(y_a1, color='red', marker='.') \nax[0, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nax[1, 0].plot(x_2, color='seagreen', marker='o') \nax[1, 0].set_title('Original Sales', fontsize=24)\nax[1, 1].plot(y_a2, color='red', marker='.') \nax[1, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nax[2, 0].plot(x_3, color='seagreen', marker='o') \nax[2, 0].set_title('Original Sales', fontsize=24)\nax[2, 1].plot(y_a3, color='red', marker='.') \nax[2, 1].set_title('After Wavelet Denoising', fontsize=24)\n\nplt.show()"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\ndf = pd.DataFrame(np.transpose([means, store_list]))\ndf.columns = [\"Mean sales\", \"Store name\"]\npx.bar(df, y=\"Mean sales\", x=\"Store name\", color=\"Store name\", title=\"Mean sales vs. Store name\")",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\ndf = pd.DataFrame(np.transpose([means, store_list]))\ndf.columns = [\"Mean sales\", \"Store name\"]\npx.bar(df, y=\"Mean sales\", x=\"Store name\", color=\"Store name\", title=\"Mean sales vs. Store name\")"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nfig = go.Figure()\n\nfor i, s in enumerate(store_list):\n    if \"ca\" in s or \"CA\" in s:\n        store_items = [c for c in past_sales.columns if s in c]\n        data = past_sales[store_items].sum(axis=1).rolling(90).mean()\n        fig.add_trace(go.Box(x=[s]*len(data), y=data, name=s, marker=dict(color=greens[i])))\n    \nfig.update_layout(yaxis_title=\"Sales\", xaxis_title=\"Time\", title=\"Rolling Average Sales vs. Store name (California)\")\ndf = pd.DataFrame(np.transpose([means, stores]))\ndf.columns = [\"Mean sales\", \"Store name\"]\npx.bar(df, y=\"Mean sales\", x=\"Store name\", color=\"Store name\", title=\"Mean sales vs. Store name\", color_continuous_scale=greens)\n\n\nfig = go.Figure(data=[\n    go.Bar(name='', x=stores, y=means, marker={'color' : greens})])\n\nfig.update_layout(title=\"Mean sales vs. Store name (California)\", yaxis=dict(title=\"Mean sales\"), xaxis=dict(title=\"Store name\"))\nfig.update_layout(barmode='group')\nfig.show()",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nfig = go.Figure()\n\nfor i, s in enumerate(store_list):\n    if \"ca\" in s or \"CA\" in s:\n        store_items = [c for c in past_sales.columns if s in c]\n        data = past_sales[store_items].sum(axis=1).rolling(90).mean()\n        fig.add_trace(go.Box(x=[s]*len(data), y=data, name=s, marker=dict(color=greens[i])))\n    \nfig.update_layout(yaxis_title=\"Sales\", xaxis_title=\"Time\", title=\"Rolling Average Sales vs. Store name (California)\")\ndf = pd.DataFrame(np.transpose([means, stores]))\ndf.columns = [\"Mean sales\", \"Store name\"]\npx.bar(df, y=\"Mean sales\", x=\"Store name\", color=\"Store name\", title=\"Mean sales vs. Store name\", color_continuous_scale=greens)\n\n\nfig = go.Figure(data=[\n    go.Bar(name='', x=stores, y=means, marker={'color' : greens})])\n\nfig.update_layout(title=\"Mean sales vs. Store name (California)\", yaxis=dict(title=\"Mean sales\"), xaxis=dict(title=\"Store name\"))\nfig.update_layout(barmode='group')\nfig.show()"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nfig = go.Figure()\n\nfor i, s in enumerate(store_list):\n    if \"wi\" in s or \"WI\" in s:\n        store_items = [c for c in past_sales.columns if s in c]\n        data = past_sales[store_items].sum(axis=1).rolling(90).mean()\n        fig.add_trace(go.Box(x=[s]*len(data), y=data, name=s, marker=dict(color=purples[i%len(purples)])))\n    \nfig.update_layout(yaxis_title=\"Sales\", xaxis_title=\"Time\", title=\"Rolling Average Sales vs. Store name (Wisconsin)\")\ndf = pd.DataFrame(np.transpose([means, stores]))\ndf.columns = [\"Mean sales\", \"Store name\"]\npx.bar(df, y=\"Mean sales\", x=\"Store name\", color=\"Store name\", title=\"Mean sales vs. Store name\", color_continuous_scale=greens)\n\n\nfig = go.Figure(data=[\n    go.Bar(name='', x=stores, y=means, marker={'color' : purples})])\n\nfig.update_layout(title=\"Mean sales vs. Store name (Wisconsin)\", yaxis=dict(title=\"Mean sales\"), xaxis=dict(title=\"Store name\"))\nfig.update_layout(barmode='group')\nfig.show()",
				"bm25Code": "# Reference: https://www.kaggle.com/code/tarunpaparaju/m5-competition-eda-models\n\nfig = go.Figure()\n\nfor i, s in enumerate(store_list):\n    if \"wi\" in s or \"WI\" in s:\n        store_items = [c for c in past_sales.columns if s in c]\n        data = past_sales[store_items].sum(axis=1).rolling(90).mean()\n        fig.add_trace(go.Box(x=[s]*len(data), y=data, name=s, marker=dict(color=purples[i%len(purples)])))\n    \nfig.update_layout(yaxis_title=\"Sales\", xaxis_title=\"Time\", title=\"Rolling Average Sales vs. Store name (Wisconsin)\")\ndf = pd.DataFrame(np.transpose([means, stores]))\ndf.columns = [\"Mean sales\", \"Store name\"]\npx.bar(df, y=\"Mean sales\", x=\"Store name\", color=\"Store name\", title=\"Mean sales vs. Store name\", color_continuous_scale=greens)\n\n\nfig = go.Figure(data=[\n    go.Bar(name='', x=stores, y=means, marker={'color' : purples})])\n\nfig.update_layout(title=\"Mean sales vs. Store name (Wisconsin)\", yaxis=dict(title=\"Mean sales\"), xaxis=dict(title=\"Store name\"))\nfig.update_layout(barmode='group')\nfig.show()"
			}
		]
	},
	"master": {
		"correct_pairs_summarize": { "ml": 405, "es": 3572, "es-processed": 3007 },
		"incorrect_pairs_items": [
			{
				"originalCode": "!pip install imagecodecs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2 \nfrom tqdm.notebook import tqdm\nimport skimage.io\nimport tensorflow as tf\nimport math\nimport glob\ndata = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv')\ninput_path = '../input/prostate-cancer-grade-assessment/train_images/'\ndata.head(3)",
				"bm25Code": "!pip install imagecodecs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2 \nfrom tqdm.notebook import tqdm\nimport skimage.io\nimport tensorflow as tf\nimport math\nimport glob\ndata = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv')\ninput_path = '../input/prostate-cancer-grade-assessment/train_images/'\ndata.head(3)"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/akensert/panda-optimized-tiling-tf-data-dataset\n\ndef _mask_tissue(image, kernel_size=(7, 7), gray_threshold=220):\n    \"\"\"Masks tissue in image. Uses gray-scaled image, as well as\n    dilation kernels and 'gap filling'\n    \"\"\"\n    # Define elliptic kernel\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)\n    # Convert rgb to gray scale for easier masking\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    # Now mask the gray-scaled image (capturing tissue in biopsy)\n    mask = np.where(gray < gray_threshold, 1, 0).astype(np.uint8)\n    # Use dilation and findContours to fill in gaps/holes in masked tissue\n    mask = cv2.dilate(mask, kernel, iterations=1)\n    contour, _ = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n    for cnt in contour:\n        cv2.drawContours(mask, [cnt], 0, 1, -1)\n    return mask\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 12))\n\nmask = _mask_tissue(image)\n\naxes[0].imshow(image)\naxes[1].imshow(mask)\naxes[0].axis('off')\naxes[1].axis('off');",
				"bm25Code": "# Reference: https://www.kaggle.com/code/akensert/panda-optimized-tiling-tf-data-dataset\n\ndef _mask_tissue(image, kernel_size=(7, 7), gray_threshold=220):\n    \"\"\"Masks tissue in image. Uses gray-scaled image, as well as\n    dilation kernels and 'gap filling'\n    \"\"\"\n    # Define elliptic kernel\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)\n    # Convert rgb to gray scale for easier masking\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    # Now mask the gray-scaled image (capturing tissue in biopsy)\n    mask = np.where(gray < gray_threshold, 1, 0).astype(np.uint8)\n    # Use dilation and findContours to fill in gaps/holes in masked tissue\n    mask = cv2.dilate(mask, kernel, iterations=1)\n    contour, _ = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n    for cnt in contour:\n        cv2.drawContours(mask, [cnt], 0, 1, -1)\n    return mask\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 12))\n\nmask = _mask_tissue(image)\n\naxes[0].imshow(image)\naxes[1].imshow(mask)\naxes[0].axis('off')\naxes[1].axis('off');"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/akensert/panda-optimized-tiling-tf-data-dataset\n\nfig, axes = plt.subplots(10, 1, figsize=(20, 140))\n\npatch_size = 256\n\nfor i, ax in enumerate(axes.reshape(-1)):\n    image_path = input_path + data.image_id[i+500] + '.tiff'\n    image = read_image(image_path, 1)\n    \n    coords = compute_coords(image,\n                            patch_size=patch_size,\n                            precompute=True,\n                            min_patch_info=0.35,\n                            min_axis_info=0.35,\n                            min_consec_axis_info=0.35,\n                            min_decimal_keep=0.7)\n    \n    # sort coords (high info -> low info)\n    coords = sorted(coords, key= lambda x: x[0], reverse=False)\n    for (v, y, x) in coords:\n        end_point = (x, y)\n        start_point = (x+patch_size, y+patch_size)\n        image = cv2.rectangle(image, start_point, end_point, 2, 14)\n    \n    ax.imshow(image)\n    ax.axis('off')\n    ax.set_title(\n        \"num patches = \"+str(len(coords))+\", isup grade = \"+str(data.isup_grade[i+500]),\n        fontsize=20)\n\nplt.subplots_adjust(hspace=0.05, wspace=0.05)",
				"bm25Code": "# Reference: https://www.kaggle.com/code/akensert/panda-optimized-tiling-tf-data-dataset\n\nfig, axes = plt.subplots(10, 1, figsize=(20, 140))\n\npatch_size = 256\n\nfor i, ax in enumerate(axes.reshape(-1)):\n    image_path = input_path + data.image_id[i+500] + '.tiff'\n    image = read_image(image_path, 1)\n    \n    coords = compute_coords(image,\n                            patch_size=patch_size,\n                            precompute=True,\n                            min_patch_info=0.35,\n                            min_axis_info=0.35,\n                            min_consec_axis_info=0.35,\n                            min_decimal_keep=0.7)\n    \n    # sort coords (high info -> low info)\n    coords = sorted(coords, key= lambda x: x[0], reverse=False)\n    for (v, y, x) in coords:\n        end_point = (x, y)\n        start_point = (x+patch_size, y+patch_size)\n        image = cv2.rectangle(image, start_point, end_point, 2, 14)\n    \n    ax.imshow(image)\n    ax.axis('off')\n    ax.set_title(\n        \"num patches = \"+str(len(coords))+\", isup grade = \"+str(data.isup_grade[i+500]),\n        fontsize=20)\n\nplt.subplots_adjust(hspace=0.05, wspace=0.05)"
			},
			{
				"originalCode": "import os \nimport sys\nimport random\nimport math\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nimport pydicom\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport pandas as pd \nimport glob\nfrom sklearn.model_selection import KFold\nDATA_DIR = '/kaggle/input'\n\n# Directory to save logs and trained model\nROOT_DIR = '/kaggle/working'",
				"bm25Code": "import os \nimport sys\nimport random\nimport math\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nimport pydicom\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport pandas as pd \nimport glob\nfrom sklearn.model_selection import KFold\nDATA_DIR = '/kaggle/input'\n\n# Directory to save logs and trained model\nROOT_DIR = '/kaggle/working'"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155\n\n# Load and display random sample and their bounding boxes\n\nclass_ids = [0]\nwhile class_ids[0] == 0:  ## look for a mask\n    image_id = random.choice(dataset_train.image_ids)\n    image_fp = dataset_train.image_reference(image_id)\n    image = dataset_train.load_image(image_id)\n    mask, class_ids = dataset_train.load_mask(image_id)\n\nprint(image.shape)\n\nplt.figure(figsize=(10, 10))\nplt.subplot(1, 2, 1)\nplt.imshow(image)\nplt.axis('off')\n\nplt.subplot(1, 2, 2)\nmasked = np.zeros(image.shape[:2])\nfor i in range(mask.shape[2]):\n    masked += image[:, :, 0] * mask[:, :, i]\nplt.imshow(masked, cmap='gray')\nplt.axis('off')\n\nprint(image_fp)\nprint(class_ids)",
				"bm25Code": "# Reference: https://www.kaggle.com/code/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155\n\n# Load and display random sample and their bounding boxes\n\nclass_ids = [0]\nwhile class_ids[0] == 0:  ## look for a mask\n    image_id = random.choice(dataset_train.image_ids)\n    image_fp = dataset_train.image_reference(image_id)\n    image = dataset_train.load_image(image_id)\n    mask, class_ids = dataset_train.load_mask(image_id)\n\nprint(image.shape)\n\nplt.figure(figsize=(10, 10))\nplt.subplot(1, 2, 1)\nplt.imshow(image)\nplt.axis('off')\n\nplt.subplot(1, 2, 2)\nmasked = np.zeros(image.shape[:2])\nfor i in range(mask.shape[2]):\n    masked += image[:, :, 0] * mask[:, :, i]\nplt.imshow(masked, cmap='gray')\nplt.axis('off')\n\nprint(image_fp)\nprint(class_ids)"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155\n\n# Image augmentation (light but constant)\naugmentation = iaa.Sequential([\n    iaa.OneOf([ ## geometric transform\n        iaa.Affine(\n            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n            rotate=(-2, 2),\n            shear=(-1, 1),\n        ),\n        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n    ]),\n    iaa.OneOf([ ## brightness or contrast\n        iaa.Multiply((0.9, 1.1)),\n        iaa.ContrastNormalization((0.9, 1.1)),\n    ]),\n    iaa.OneOf([ ## blur or sharpen\n        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n        iaa.Sharpen(alpha=(0.0, 0.1)),\n    ]),\n])\n\n# test on the same image as above\nimggrid = augmentation.draw_grid(image[:, :, 0], cols=5, rows=2)\nplt.figure(figsize=(30, 12))\n_ = plt.imshow(imggrid[:, :, 0], cmap='gray')",
				"bm25Code": "# Reference: https://www.kaggle.com/code/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155\n\n# Image augmentation (light but constant)\naugmentation = iaa.Sequential([\n    iaa.OneOf([ ## geometric transform\n        iaa.Affine(\n            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n            rotate=(-2, 2),\n            shear=(-1, 1),\n        ),\n        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n    ]),\n    iaa.OneOf([ ## brightness or contrast\n        iaa.Multiply((0.9, 1.1)),\n        iaa.ContrastNormalization((0.9, 1.1)),\n    ]),\n    iaa.OneOf([ ## blur or sharpen\n        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n        iaa.Sharpen(alpha=(0.0, 0.1)),\n    ]),\n])\n\n# test on the same image as above\nimggrid = augmentation.draw_grid(image[:, :, 0], cols=5, rows=2)\nplt.figure(figsize=(30, 12))\n_ = plt.imshow(imggrid[:, :, 0], cmap='gray')"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155\n\nmodel = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)\n\n# Exclude the last layers because they require a matching\n# number of classes\nmodel.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n    \"mrcnn_bbox\", \"mrcnn_mask\"])\nLEARNING_RATE = 0.006\n\n# Train Mask-RCNN Model \nimport warnings \nwarnings.filterwarnings(\"ignore\")\n%%time\n## train heads with higher lr to speedup the learning\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE*2,\n            epochs=2,\n            layers='heads',\n            augmentation=None)  ## no need to augment yet\n\nhistory = model.keras_model.history.history\n%%time\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE,\n            epochs=6,\n            layers='all',\n            augmentation=augmentation)\n\nnew_history = model.keras_model.history.history\nfor k in new_history: history[k] = history[k] + new_history[k]\n%%time\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE/5,\n            epochs=16,\n            layers='all',\n            augmentation=augmentation)\n\nnew_history = model.keras_model.history.history\nfor k in new_history: history[k] = history[k] + new_history[k]\nepochs = range(1,len(next(iter(history.values())))+1)\npd.DataFrame(history, index=epochs)\nplt.figure(figsize=(17,5))\n\nplt.subplot(131)\nplt.plot(epochs, history[\"loss\"], label=\"Train loss\")\nplt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\nplt.legend()\nplt.subplot(132)\nplt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"Train class ce\")\nplt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"Valid class ce\")\nplt.legend()\nplt.subplot(133)\nplt.plot(epochs, history[\"mrcnn_bbox_loss\"], label=\"Train box loss\")\nplt.plot(epochs, history[\"val_mrcnn_bbox_loss\"], label=\"Valid box loss\")\nplt.legend()\n\nplt.show()\nbest_epoch = np.argmin(history[\"val_loss\"])\nprint(\"Best Epoch:\", best_epoch + 1, history[\"val_loss\"][best_epoch])\n# select trained model \ndir_names = next(os.walk(model.model_dir))[1]\nkey = config.NAME.lower()\ndir_names = filter(lambda f: f.startswith(key), dir_names)\ndir_names = sorted(dir_names)\n\nif not dir_names:\n    import errno\n    raise FileNotFoundError(\n        errno.ENOENT,\n        \"Could not find model directory under {}\".format(self.model_dir))\n    \nfps = []\n# Pick last directory\nfor d in dir_names: \n    dir_name = os.path.join(model.model_dir, d)\n    # Find the last checkpoint\n    checkpoints = next(os.walk(dir_name))[2]\n    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n    checkpoints = sorted(checkpoints)\n    if not checkpoints:\n        print('No weight files in {}'.format(dir_name))\n    else:\n        checkpoint = os.path.join(dir_name, checkpoints[best_epoch])\n        fps.append(checkpoint)\n\nmodel_path = sorted(fps)[-1]\nprint('Found model {}'.format(model_path))\nclass InferenceConfig(DetectorConfig):\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\ninference_config = InferenceConfig()\n\n# Recreate the model in inference mode\nmodel = modellib.MaskRCNN(mode='inference', \n                          config=inference_config,\n                          model_dir=ROOT_DIR)\n\n# Load trained weights (fill in path to trained weights here)\nassert model_path != \"\", \"Provide path to trained weights\"\nprint(\"Loading weights from \", model_path)\nmodel.load_weights(model_path, by_name=True)\n# set color for class\ndef get_colors_for_class_ids(class_ids):\n    colors = []\n    for class_id in class_ids:\n        if class_id == 1:\n            colors.append((.941, .204, .204))\n    return colors",
				"bm25Code": "# Reference: https://www.kaggle.com/code/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155\n\nmodel = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)\n\n# Exclude the last layers because they require a matching\n# number of classes\nmodel.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n    \"mrcnn_bbox\", \"mrcnn_mask\"])\nLEARNING_RATE = 0.006\n\n# Train Mask-RCNN Model \nimport warnings \nwarnings.filterwarnings(\"ignore\")\n%%time\n## train heads with higher lr to speedup the learning\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE*2,\n            epochs=2,\n            layers='heads',\n            augmentation=None)  ## no need to augment yet\n\nhistory = model.keras_model.history.history\n%%time\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE,\n            epochs=6,\n            layers='all',\n            augmentation=augmentation)\n\nnew_history = model.keras_model.history.history\nfor k in new_history: history[k] = history[k] + new_history[k]\n%%time\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE/5,\n            epochs=16,\n            layers='all',\n            augmentation=augmentation)\n\nnew_history = model.keras_model.history.history\nfor k in new_history: history[k] = history[k] + new_history[k]\nepochs = range(1,len(next(iter(history.values())))+1)\npd.DataFrame(history, index=epochs)\nplt.figure(figsize=(17,5))\n\nplt.subplot(131)\nplt.plot(epochs, history[\"loss\"], label=\"Train loss\")\nplt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\nplt.legend()\nplt.subplot(132)\nplt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"Train class ce\")\nplt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"Valid class ce\")\nplt.legend()\nplt.subplot(133)\nplt.plot(epochs, history[\"mrcnn_bbox_loss\"], label=\"Train box loss\")\nplt.plot(epochs, history[\"val_mrcnn_bbox_loss\"], label=\"Valid box loss\")\nplt.legend()\n\nplt.show()\nbest_epoch = np.argmin(history[\"val_loss\"])\nprint(\"Best Epoch:\", best_epoch + 1, history[\"val_loss\"][best_epoch])\n# select trained model \ndir_names = next(os.walk(model.model_dir))[1]\nkey = config.NAME.lower()\ndir_names = filter(lambda f: f.startswith(key), dir_names)\ndir_names = sorted(dir_names)\n\nif not dir_names:\n    import errno\n    raise FileNotFoundError(\n        errno.ENOENT,\n        \"Could not find model directory under {}\".format(self.model_dir))\n    \nfps = []\n# Pick last directory\nfor d in dir_names: \n    dir_name = os.path.join(model.model_dir, d)\n    # Find the last checkpoint\n    checkpoints = next(os.walk(dir_name))[2]\n    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n    checkpoints = sorted(checkpoints)\n    if not checkpoints:\n        print('No weight files in {}'.format(dir_name))\n    else:\n        checkpoint = os.path.join(dir_name, checkpoints[best_epoch])\n        fps.append(checkpoint)\n\nmodel_path = sorted(fps)[-1]\nprint('Found model {}'.format(model_path))\nclass InferenceConfig(DetectorConfig):\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\ninference_config = InferenceConfig()\n\n# Recreate the model in inference mode\nmodel = modellib.MaskRCNN(mode='inference', \n                          config=inference_config,\n                          model_dir=ROOT_DIR)\n\n# Load trained weights (fill in path to trained weights here)\nassert model_path != \"\", \"Provide path to trained weights\"\nprint(\"Loading weights from \", model_path)\nmodel.load_weights(model_path, by_name=True)\n# set color for class\ndef get_colors_for_class_ids(class_ids):\n    colors = []\n    for class_id in class_ids:\n        if class_id == 1:\n            colors.append((.941, .204, .204))\n    return colors"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155\n\n# Show few example of ground truth vs. predictions on the validation dataset \ndataset = dataset_val\nfig = plt.figure(figsize=(10, 30))\n\nfor i in range(6):\n\n    image_id = random.choice(dataset.image_ids)\n    \n    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n        modellib.load_image_gt(dataset_val, inference_config, \n                               image_id, use_mini_mask=False)\n    \n    print(original_image.shape)\n    plt.subplot(6, 2, 2*i + 1)\n    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n                                dataset.class_names,\n                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n    \n    plt.subplot(6, 2, 2*i + 2)\n    results = model.detect([original_image]) #, verbose=1)\n    r = results[0]\n    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n                                dataset.class_names, r['scores'], \n                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])\n# Get filenames of test dataset DICOM images\ntest_image_fps = get_dicom_fps(test_dicom_dir)",
				"bm25Code": "# Reference: https://www.kaggle.com/code/hmendonca/mask-rcnn-and-coco-transfer-learning-lb-0-155\n\n# Show few example of ground truth vs. predictions on the validation dataset \ndataset = dataset_val\nfig = plt.figure(figsize=(10, 30))\n\nfor i in range(6):\n\n    image_id = random.choice(dataset.image_ids)\n    \n    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n        modellib.load_image_gt(dataset_val, inference_config, \n                               image_id, use_mini_mask=False)\n    \n    print(original_image.shape)\n    plt.subplot(6, 2, 2*i + 1)\n    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n                                dataset.class_names,\n                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n    \n    plt.subplot(6, 2, 2*i + 2)\n    results = model.detect([original_image]) #, verbose=1)\n    r = results[0]\n    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n                                dataset.class_names, r['scores'], \n                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])\n# Get filenames of test dataset DICOM images\ntest_image_fps = get_dicom_fps(test_dicom_dir)"
			},
			{
				"originalCode": "# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Modeling\nimport lightgbm as lgb\n\n# Evaluation of the model\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['font.size'] = 18\n%matplotlib inline\n\n# Governing choices for search\nN_FOLDS = 5\nMAX_EVALS = 5",
				"bm25Code": "# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Modeling\nimport lightgbm as lgb\n\n# Evaluation of the model\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['font.size'] = 18\n%matplotlib inline\n\n# Governing choices for search\nN_FOLDS = 5\nMAX_EVALS = 5"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/willkoehrsen/automated-model-tuning\n\nlearning_rate_dist = []\n\n# Draw 10000 samples from the learning rate domain\nfor _ in range(10000):\n    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n    \nplt.figure(figsize = (8, 6))\nsns.kdeplot(learning_rate_dist, color = 'red', linewidth = 2, shade = True);\nplt.title('Learning Rate Distribution', size = 18); plt.xlabel('Learning Rate', size = 16); plt.ylabel('Density', size = 16);",
				"bm25Code": "# Reference: https://www.kaggle.com/code/willkoehrsen/automated-model-tuning\n\nlearning_rate_dist = []\n\n# Draw 10000 samples from the learning rate domain\nfor _ in range(10000):\n    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n    \nplt.figure(figsize = (8, 6))\nsns.kdeplot(learning_rate_dist, color = 'red', linewidth = 2, shade = True);\nplt.title('Learning Rate Distribution', size = 18); plt.xlabel('Learning Rate', size = 16); plt.ylabel('Density', size = 16);"
			}
		]
	},
	"expert": {
		"correct_pairs_summarize": { "ml": 658, "es": 9187, "es-processed": 7191 },
		"incorrect_pairs_items": [
			{
				"originalCode": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n!conda install -y gdcm -c conda-forge\nimport pydicom\nimport math\nimport PIL\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nimport tensorflow as tf\nfrom tqdm import tqdm\n%matplotlib inline\nfrom scipy.stats import shapiro\nfrom scipy import stats \nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport pickle\nimport gc",
				"bm25Code": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n!conda install -y gdcm -c conda-forge\nimport pydicom\nimport math\nimport PIL\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nimport tensorflow as tf\nfrom tqdm import tqdm\n%matplotlib inline\nfrom scipy.stats import shapiro\nfrom scipy import stats \nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport pickle\nimport gc"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\nplt.hist(train_df['FVC'])\n# https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/\n# normality test\nstat, p = shapiro(train_df['FVC'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.01\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')",
				"bm25Code": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\nplt.hist(train_df['FVC'])\n# https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/\n# normality test\nstat, p = shapiro(train_df['FVC'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.01\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\n# transform training data & save lambda value \n_, fitted_lambda = stats.boxcox(train_df['FVC']) \nprint(\"solved lambda: \", fitted_lambda)\ndef BoxCoxTransform(x, lmbda):\n    part1 = x**lmbda\n    part2 = part1-1\n    result = part2/lmbda\n    return result\n\ndef ReverseBoxCoxTranform(x, lmbda):\n    x = np.where(x<0,0,x)\n    part1 = x*lmbda + 1\n    result = part1**(1/lmbda)\n    return result\nfitted_data = BoxCoxTransform(train_df['FVC'], lmbda=fitted_lambda)\nplt.hist(fitted_data)\n# https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/\n# normality test\nstat, p = shapiro(fitted_data)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.01\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')\n# show that we can reverse transformed values back to original values\nplt.hist(ReverseBoxCoxTranform(fitted_data, lmbda=fitted_lambda))",
				"bm25Code": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\n# transform training data & save lambda value \n_, fitted_lambda = stats.boxcox(train_df['FVC']) \nprint(\"solved lambda: \", fitted_lambda)\ndef BoxCoxTransform(x, lmbda):\n    part1 = x**lmbda\n    part2 = part1-1\n    result = part2/lmbda\n    return result\n\ndef ReverseBoxCoxTranform(x, lmbda):\n    x = np.where(x<0,0,x)\n    part1 = x*lmbda + 1\n    result = part1**(1/lmbda)\n    return result\nfitted_data = BoxCoxTransform(train_df['FVC'], lmbda=fitted_lambda)\nplt.hist(fitted_data)\n# https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/\n# normality test\nstat, p = shapiro(fitted_data)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.01\nif p > alpha:\n    print('Sample looks Gaussian (fail to reject H0)')\nelse:\n    print('Sample does not look Gaussian (reject H0)')\n# show that we can reverse transformed values back to original values\nplt.hist(ReverseBoxCoxTranform(fitted_data, lmbda=fitted_lambda))"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\nx_train_fvc, x_val_fvc, y_train_fvc, y_val_fvc = train_test_split(\n    x_train_full, BoxCoxTransform(train_df['FVC'], lmbda=fitted_lambda),\n    test_size=TRAIN_VAL_RATIO, \n    random_state=2020\n)\nwith strategy.scope():\n    # define structure\n    xin = tf.keras.layers.Input(shape=(x_train_full.shape[1], ))\n    xout = tf.keras.layers.Dense(1, activation='linear')(xin)\n    # put it together\n    model1 = tf.keras.Model(inputs=xin, outputs=xout)\n    # compile\n    opt = tf.optimizers.RMSprop(LR)\n    model1.compile(optimizer=opt, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n# print summary\nmodel1.summary()\n### define callbacks\nearlystopper = EarlyStopping(\n    monitor='val_mean_squared_error', \n    patience=30,\n    verbose=1,\n    mode='min'\n)\n\nlrreducer = ReduceLROnPlateau(\n    monitor='val_mean_squared_error',\n    factor=.5,\n    patience=10,\n    verbose=1,\n    min_lr=1e-9\n)\nprint(\"Fit model on training data\")\nhistory = model1.fit(\n    x_train_fvc,\n    y_train_fvc,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS_M1,\n    validation_data=(x_val_fvc, y_val_fvc),\n    callbacks=[earlystopper,lrreducer]\n)\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['mean_squared_error', 'val_mean_squared_error']].plot()\ntrain_df['FVC_pred1'] = ReverseBoxCoxTranform(model1.predict(x_train_full), lmbda=fitted_lambda)\ntrain_df.head()\nstats.describe(model1.predict(x_train_full))",
				"bm25Code": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\nx_train_fvc, x_val_fvc, y_train_fvc, y_val_fvc = train_test_split(\n    x_train_full, BoxCoxTransform(train_df['FVC'], lmbda=fitted_lambda),\n    test_size=TRAIN_VAL_RATIO, \n    random_state=2020\n)\nwith strategy.scope():\n    # define structure\n    xin = tf.keras.layers.Input(shape=(x_train_full.shape[1], ))\n    xout = tf.keras.layers.Dense(1, activation='linear')(xin)\n    # put it together\n    model1 = tf.keras.Model(inputs=xin, outputs=xout)\n    # compile\n    opt = tf.optimizers.RMSprop(LR)\n    model1.compile(optimizer=opt, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n# print summary\nmodel1.summary()\n### define callbacks\nearlystopper = EarlyStopping(\n    monitor='val_mean_squared_error', \n    patience=30,\n    verbose=1,\n    mode='min'\n)\n\nlrreducer = ReduceLROnPlateau(\n    monitor='val_mean_squared_error',\n    factor=.5,\n    patience=10,\n    verbose=1,\n    min_lr=1e-9\n)\nprint(\"Fit model on training data\")\nhistory = model1.fit(\n    x_train_fvc,\n    y_train_fvc,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS_M1,\n    validation_data=(x_val_fvc, y_val_fvc),\n    callbacks=[earlystopper,lrreducer]\n)\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['mean_squared_error', 'val_mean_squared_error']].plot()\ntrain_df['FVC_pred1'] = ReverseBoxCoxTranform(model1.predict(x_train_full), lmbda=fitted_lambda)\ntrain_df.head()\nstats.describe(model1.predict(x_train_full))"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\n%%time\n\nbest_confidence = np.zeros(len(train_df))\nBestRandSearchScore = -1000000000\nscorehist = []\nprint(\"running random search...\")\nfor i in range(10000):\n    trial_confidence = np.random.randint(70, 1000, size=len(train_df))\n    train_df['Confidence'] = trial_confidence\n    train_df['sigma_clipped'] = train_df['Confidence'].apply(lambda x: max(x, 70))\n    train_df['diff'] = abs(train_df['FVC'] - train_df['FVC_pred1'])\n    train_df['delta'] = train_df['diff'].apply(lambda x: min(x, 1000))\n    train_df['score'] = -math.sqrt(2)*train_df['delta']/train_df['sigma_clipped'] - np.log(math.sqrt(2)*train_df['sigma_clipped'])\n    score = train_df['score'].mean()\n    if score>BestRandSearchScore:\n        BestRandSearchScore = score\n        best_confidence = trial_confidence\n        print(\"best confidence values found in round {} with best score of {}\".format(i,score))\n    scorehist.append(BestRandSearchScore)\nplt.plot(scorehist)\nplt.ylabel('best score')\nplt.xlabel('round')\nplt.show()",
				"bm25Code": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\n%%time\n\nbest_confidence = np.zeros(len(train_df))\nBestRandSearchScore = -1000000000\nscorehist = []\nprint(\"running random search...\")\nfor i in range(10000):\n    trial_confidence = np.random.randint(70, 1000, size=len(train_df))\n    train_df['Confidence'] = trial_confidence\n    train_df['sigma_clipped'] = train_df['Confidence'].apply(lambda x: max(x, 70))\n    train_df['diff'] = abs(train_df['FVC'] - train_df['FVC_pred1'])\n    train_df['delta'] = train_df['diff'].apply(lambda x: min(x, 1000))\n    train_df['score'] = -math.sqrt(2)*train_df['delta']/train_df['sigma_clipped'] - np.log(math.sqrt(2)*train_df['sigma_clipped'])\n    score = train_df['score'].mean()\n    if score>BestRandSearchScore:\n        BestRandSearchScore = score\n        best_confidence = trial_confidence\n        print(\"best confidence values found in round {} with best score of {}\".format(i,score))\n    scorehist.append(BestRandSearchScore)\nplt.plot(scorehist)\nplt.ylabel('best score')\nplt.xlabel('round')\nplt.show()"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\n# x_train, x_val, y_train1, y_val1, y_train2, y_val2 = train_test_split(\n#     x_train_full, \n#     best_confidence,\n#     BoxCoxTransform(train_df['FVC'], lmbda=fitted_lambda), \n#     test_size=TRAIN_VAL_RATIO, \n#     random_state=2020\n# )\n\nx_train, x_val, y_train, y_val = train_test_split(\n    x_train_full, \n    best_confidence,\n    test_size=TRAIN_VAL_RATIO, \n    random_state=2020\n)\n# def Laplace_Log_Likelihood(y_true, y_pred):\n#     # get predictions\n#     y_pred1 = tf.cast(y_pred[:,0], dtype=tf.float32) # confidence\n#     y_pred2 = tf.cast(y_pred[:,1], dtype=tf.float32) # fvc\n#     # reverse box cox\n#     tfz = tf.cast(tf.constant([0]), dtype=tf.float32) \n#     y_pred2 = tf.where(y_pred2<tfz,tfz,y_pred1)\n#     lbda = tf.cast(tf.constant([0.376401998544658]), dtype=tf.float32) \n#     tf1 = tf.cast(tf.constant([1]), dtype=tf.float32)\n#     p1 = tf.math.add(tf.math.multiply(y_pred2,lbda), tf1)\n#     y_pred2 = tf.pow(p1,tf.math.divide(tf1,lbda)) # fvc reverse box cox\n#     # laplace log likelihood                \n#     threshold = tf.cast(tf.constant([70]), dtype=tf.float32) \n#     sig_clip = tf.math.maximum(y_pred1, threshold)\n#     threshold = tf.cast(tf.constant([1000]), dtype=tf.float32) \n#     delta = tf.math.minimum(tf.math.abs(tf.math.subtract(y_true,y_pred2)),threshold)\n#     sqrt2 = tf.cast(tf.constant([1.4142135623730951]), dtype=tf.float32) \n#     numerator = tf.math.multiply(sqrt2,delta)\n#     part1 = tf.math.divide(numerator,sig_clip)\n#     innerlog = tf.math.multiply(sqrt2,sig_clip)\n#     metric = tf.math.subtract(-part1,tf.math.log(innerlog))\n#     return tf.math.reduce_mean(metric)\nwith strategy.scope():\n    # define structure\n    xin = tf.keras.layers.Input(shape=(x_train_full.shape[1], ))\n    xout = tf.keras.layers.Dense(1, activation='linear')(xin)\n    # put it together\n    model2 = tf.keras.Model(inputs=xin, outputs=xout)\n    # compile\n    opt = tf.optimizers.RMSprop(LR)\n    model2.compile(optimizer=opt, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n# print summary\nmodel2.summary()\n### define callbacks\nearlystopper = EarlyStopping(\n    monitor='val_mean_squared_error', \n    patience=3,\n    verbose=1,\n    mode='min'\n)\n\nlrreducer = ReduceLROnPlateau(\n    monitor='val_mean_squared_error',\n    factor=.5,\n    patience=2,\n    verbose=1,\n    min_lr=1e-9\n)\nprint(\"Fit model on training data\")\nhistory = model2.fit(\n    x_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS_M2,\n    validation_data=(x_val, y_val),\n    callbacks=[earlystopper,lrreducer]\n)\nmodel2.save('model.h5')\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['mean_squared_error', 'val_mean_squared_error']].plot()\n# history_df[['Laplace_Log_Likelihood', 'val_Laplace_Log_Likelihood']].plot()\nmodel2.predict(x_test_full)",
				"bm25Code": "# Reference: https://www.kaggle.com/code/yeayates21/osic-image-data-prep-and-baseline-regression-model\n\n# x_train, x_val, y_train1, y_val1, y_train2, y_val2 = train_test_split(\n#     x_train_full, \n#     best_confidence,\n#     BoxCoxTransform(train_df['FVC'], lmbda=fitted_lambda), \n#     test_size=TRAIN_VAL_RATIO, \n#     random_state=2020\n# )\n\nx_train, x_val, y_train, y_val = train_test_split(\n    x_train_full, \n    best_confidence,\n    test_size=TRAIN_VAL_RATIO, \n    random_state=2020\n)\n# def Laplace_Log_Likelihood(y_true, y_pred):\n#     # get predictions\n#     y_pred1 = tf.cast(y_pred[:,0], dtype=tf.float32) # confidence\n#     y_pred2 = tf.cast(y_pred[:,1], dtype=tf.float32) # fvc\n#     # reverse box cox\n#     tfz = tf.cast(tf.constant([0]), dtype=tf.float32) \n#     y_pred2 = tf.where(y_pred2<tfz,tfz,y_pred1)\n#     lbda = tf.cast(tf.constant([0.376401998544658]), dtype=tf.float32) \n#     tf1 = tf.cast(tf.constant([1]), dtype=tf.float32)\n#     p1 = tf.math.add(tf.math.multiply(y_pred2,lbda), tf1)\n#     y_pred2 = tf.pow(p1,tf.math.divide(tf1,lbda)) # fvc reverse box cox\n#     # laplace log likelihood                \n#     threshold = tf.cast(tf.constant([70]), dtype=tf.float32) \n#     sig_clip = tf.math.maximum(y_pred1, threshold)\n#     threshold = tf.cast(tf.constant([1000]), dtype=tf.float32) \n#     delta = tf.math.minimum(tf.math.abs(tf.math.subtract(y_true,y_pred2)),threshold)\n#     sqrt2 = tf.cast(tf.constant([1.4142135623730951]), dtype=tf.float32) \n#     numerator = tf.math.multiply(sqrt2,delta)\n#     part1 = tf.math.divide(numerator,sig_clip)\n#     innerlog = tf.math.multiply(sqrt2,sig_clip)\n#     metric = tf.math.subtract(-part1,tf.math.log(innerlog))\n#     return tf.math.reduce_mean(metric)\nwith strategy.scope():\n    # define structure\n    xin = tf.keras.layers.Input(shape=(x_train_full.shape[1], ))\n    xout = tf.keras.layers.Dense(1, activation='linear')(xin)\n    # put it together\n    model2 = tf.keras.Model(inputs=xin, outputs=xout)\n    # compile\n    opt = tf.optimizers.RMSprop(LR)\n    model2.compile(optimizer=opt, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanSquaredError()])\n# print summary\nmodel2.summary()\n### define callbacks\nearlystopper = EarlyStopping(\n    monitor='val_mean_squared_error', \n    patience=3,\n    verbose=1,\n    mode='min'\n)\n\nlrreducer = ReduceLROnPlateau(\n    monitor='val_mean_squared_error',\n    factor=.5,\n    patience=2,\n    verbose=1,\n    min_lr=1e-9\n)\nprint(\"Fit model on training data\")\nhistory = model2.fit(\n    x_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS_M2,\n    validation_data=(x_val, y_val),\n    callbacks=[earlystopper,lrreducer]\n)\nmodel2.save('model.h5')\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['mean_squared_error', 'val_mean_squared_error']].plot()\n# history_df[['Laplace_Log_Likelihood', 'val_Laplace_Log_Likelihood']].plot()\nmodel2.predict(x_test_full)"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/lavanyashukla01/clustering-lyft\n\ndef get_sample_tokens(log_token):\n    scene_df =  pd.DataFrame(LYFT.scene)\n    scene_df =  scene_df[scene_df['log_token']==log_token]\n    scene_df.rename(columns={'token':'scene_token'}, inplace=True)\n\n    sample_df = pd.DataFrame(LYFT.sample)\n\n    s_df = pd.merge(sample_df, scene_df, left_on='scene_token', right_on='scene_token',how='inner')\n    s_df = s_df.iloc[:10]\n    return s_df['token']\n\n\n# Compute rough accuracy and mean IOU for given hyperparameters\ndef score_clustering(eps, min_samples):\n    log_token= '71dfb15d2f88bf2aab2c5d4800c0d10a76c279b9fda98720781a406cbacc583b'\n    tokens = get_sample_tokens(log_token)\n    tokens = tokens[:2]\n    batch_input = extract_data_for_clustering(tokens)\n    \n    ious = []\n    numcorrect = 0\n    total = 0\n    pred = 0\n    for sample_token in tokens:\n        token_input = batch_input[batch_input['sample_token'] == sample_token]\n        pointcloud, has_rows, proposals_df = identify_clusters(sample_token, token_input, DATA_PATH, eps=eps, min_samples=min_samples)\n        sampledata_token = token_input.iloc[0]['sampledata_token']\n        pred = pred + len(proposals_df)\n        boxes = LYFT.get_boxes(sampledata_token)\n        \n        for i  in range(len(boxes)):\n            total = total+1\n    \n            matches = 0\n            box = boxes[i]\n            act_corners = box.corners().T\n            for j in range(len(proposals_df)):\n                pred_corners = np.array(proposals_df.iloc[j]['corners'])\n                ioveru = iou(act_corners, pred_corners)\n                if ioveru > 0:\n                    matches = matches + 1\n                    ious.append(ioveru)\n            if (matches == 1):\n                numcorrect = numcorrect + 1\n            if (matches == 0):\n                ious.append(0)\n    print(\"eps:%.2f min_samples:%d -> correct:%d actual:%d  pred %d acc:%.4f mean-iou:%.4f max-iou:%.4f\"% (eps, min_samples , numcorrect, total, pred, numcorrect / total, np.mean(ious), np.max(ious))  )\n\n# Render points , actual and proposed bounding boxes in 3d \ndef render_clustering(eps, min_samples):\n    log_token= '71dfb15d2f88bf2aab2c5d4800c0d10a76c279b9fda98720781a406cbacc583b'\n    tokens = get_sample_tokens(log_token)\n    tokens = tokens[:2]\n    batch_input = extract_data_for_clustering(tokens)\n    sample_token = tokens[0]\n    token_input = batch_input[batch_input['sample_token'] == sample_token]\n    sampledata_token = token_input.iloc[0]['sampledata_token']\n    pointcloud, has_rows, proposals_df = identify_clusters(sample_token, token_input, DATA_PATH, eps=eps, min_samples=min_samples)\n    plt = render_act_vs_pred_boxes_in_world(pointcloud, LYFT.get_boxes(sampledata_token), proposals_df['corners'])\n    print(pointcloud)",
				"bm25Code": "# Reference: https://www.kaggle.com/code/lavanyashukla01/clustering-lyft\n\ndef get_sample_tokens(log_token):\n    scene_df =  pd.DataFrame(LYFT.scene)\n    scene_df =  scene_df[scene_df['log_token']==log_token]\n    scene_df.rename(columns={'token':'scene_token'}, inplace=True)\n\n    sample_df = pd.DataFrame(LYFT.sample)\n\n    s_df = pd.merge(sample_df, scene_df, left_on='scene_token', right_on='scene_token',how='inner')\n    s_df = s_df.iloc[:10]\n    return s_df['token']\n\n\n# Compute rough accuracy and mean IOU for given hyperparameters\ndef score_clustering(eps, min_samples):\n    log_token= '71dfb15d2f88bf2aab2c5d4800c0d10a76c279b9fda98720781a406cbacc583b'\n    tokens = get_sample_tokens(log_token)\n    tokens = tokens[:2]\n    batch_input = extract_data_for_clustering(tokens)\n    \n    ious = []\n    numcorrect = 0\n    total = 0\n    pred = 0\n    for sample_token in tokens:\n        token_input = batch_input[batch_input['sample_token'] == sample_token]\n        pointcloud, has_rows, proposals_df = identify_clusters(sample_token, token_input, DATA_PATH, eps=eps, min_samples=min_samples)\n        sampledata_token = token_input.iloc[0]['sampledata_token']\n        pred = pred + len(proposals_df)\n        boxes = LYFT.get_boxes(sampledata_token)\n        \n        for i  in range(len(boxes)):\n            total = total+1\n    \n            matches = 0\n            box = boxes[i]\n            act_corners = box.corners().T\n            for j in range(len(proposals_df)):\n                pred_corners = np.array(proposals_df.iloc[j]['corners'])\n                ioveru = iou(act_corners, pred_corners)\n                if ioveru > 0:\n                    matches = matches + 1\n                    ious.append(ioveru)\n            if (matches == 1):\n                numcorrect = numcorrect + 1\n            if (matches == 0):\n                ious.append(0)\n    print(\"eps:%.2f min_samples:%d -> correct:%d actual:%d  pred %d acc:%.4f mean-iou:%.4f max-iou:%.4f\"% (eps, min_samples , numcorrect, total, pred, numcorrect / total, np.mean(ious), np.max(ious))  )\n\n# Render points , actual and proposed bounding boxes in 3d \ndef render_clustering(eps, min_samples):\n    log_token= '71dfb15d2f88bf2aab2c5d4800c0d10a76c279b9fda98720781a406cbacc583b'\n    tokens = get_sample_tokens(log_token)\n    tokens = tokens[:2]\n    batch_input = extract_data_for_clustering(tokens)\n    sample_token = tokens[0]\n    token_input = batch_input[batch_input['sample_token'] == sample_token]\n    sampledata_token = token_input.iloc[0]['sampledata_token']\n    pointcloud, has_rows, proposals_df = identify_clusters(sample_token, token_input, DATA_PATH, eps=eps, min_samples=min_samples)\n    plt = render_act_vs_pred_boxes_in_world(pointcloud, LYFT.get_boxes(sampledata_token), proposals_df['corners'])\n    print(pointcloud)"
			},
			{
				"originalCode": "#### Set number of epochs and learning rate ####\n\nset_epochs = 2\nset_lr = 1e-4\nimport numpy as np\nimport pandas as pd\nimport os\nimport skimage.io\nfrom glob import glob\nfrom random import shuffle\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport keras.backend as K\nfrom keras import layers,Input\n\nfrom keras.models import Model\nfrom keras.applications.nasnet import  preprocess_input\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom imgaug import augmenters as iaa\nimport imgaug as ia\nprint(os.listdir(\"../input/\"))\n",
				"bm25Code": "#### Set number of epochs and learning rate ####\n\nset_epochs = 2\nset_lr = 1e-4\nimport numpy as np\nimport pandas as pd\nimport os\nimport skimage.io\nfrom glob import glob\nfrom random import shuffle\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport keras.backend as K\nfrom keras import layers,Input\n\nfrom keras.models import Model\nfrom keras.applications.nasnet import  preprocess_input\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom imgaug import augmenters as iaa\nimport imgaug as ia\nprint(os.listdir(\"../input/\"))\n"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/gowrishankarin/diabetic-retinopathy-explore-plotly-cv2\n\ntrain_df = pd.read_csv(\"../input/train.csv\")\nprint(\"Shape of train data: {0}\".format(train_df.shape))\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Shape of test data: {0}\".format(test_df.shape))\n\ndiagnosis_df = pd.DataFrame({\n    'diagnosis': [0, 1, 2, 3, 4],\n    'diagnosis_label': ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative DR']\n})\n\ntrain_df = train_df.merge(diagnosis_df, how=\"left\", on=\"diagnosis\")\n\ntrain_image_files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\"../input/train_images\")) for f in fn]\ntrain_images_df = pd.DataFrame({\n    'files': train_image_files,\n    'id_code': [file.split('/')[3].split('.')[0] for file in train_image_files],\n})\ntrain_df = train_df.merge(train_images_df, how=\"left\", on=\"id_code\")\ndel train_images_df\nprint(\"Shape of train data: {0}\".format(train_df.shape))\n\ntest_image_files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\"../input/test_images\")) for f in fn]\ntest_images_df = pd.DataFrame({\n    'files': test_image_files,\n    'id_code': [file.split('/')[3].split('.')[0] for file in test_image_files],\n})\n\n\ntest_df = test_df.merge(test_images_df, how=\"left\", on=\"id_code\")\ndel test_images_df\nprint(\"Shape of test data: {0}\".format(test_df.shape))\n\n\ntrain_df.head()\ntest_df.head()\nprint(\"Number of unique diagnosis: {0}\".format(train_df.diagnosis.nunique()))\ndiagnosis_count = train_df.diagnosis.value_counts()\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 9999\npd.options.display.float_format = '{:20, .2f}'.format",
				"bm25Code": "# Reference: https://www.kaggle.com/code/gowrishankarin/diabetic-retinopathy-explore-plotly-cv2\n\ntrain_df = pd.read_csv(\"../input/train.csv\")\nprint(\"Shape of train data: {0}\".format(train_df.shape))\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Shape of test data: {0}\".format(test_df.shape))\n\ndiagnosis_df = pd.DataFrame({\n    'diagnosis': [0, 1, 2, 3, 4],\n    'diagnosis_label': ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative DR']\n})\n\ntrain_df = train_df.merge(diagnosis_df, how=\"left\", on=\"diagnosis\")\n\ntrain_image_files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\"../input/train_images\")) for f in fn]\ntrain_images_df = pd.DataFrame({\n    'files': train_image_files,\n    'id_code': [file.split('/')[3].split('.')[0] for file in train_image_files],\n})\ntrain_df = train_df.merge(train_images_df, how=\"left\", on=\"id_code\")\ndel train_images_df\nprint(\"Shape of train data: {0}\".format(train_df.shape))\n\ntest_image_files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\"../input/test_images\")) for f in fn]\ntest_images_df = pd.DataFrame({\n    'files': test_image_files,\n    'id_code': [file.split('/')[3].split('.')[0] for file in test_image_files],\n})\n\n\ntest_df = test_df.merge(test_images_df, how=\"left\", on=\"id_code\")\ndel test_images_df\nprint(\"Shape of test data: {0}\".format(test_df.shape))\n\n\ntrain_df.head()\ntest_df.head()\nprint(\"Number of unique diagnosis: {0}\".format(train_df.diagnosis.nunique()))\ndiagnosis_count = train_df.diagnosis.value_counts()\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 9999\npd.options.display.float_format = '{:20, .2f}'.format"
			},
			{
				"originalCode": "# Reference: https://www.kaggle.com/code/gowrishankarin/diabetic-retinopathy-explore-plotly-cv2\n\ndef render_bar_chart(data_df, column_name, title, filename):\n    series = data_df[column_name].value_counts()\n    count = series.shape[0]\n    \n    trace = go.Bar(x = series.index, y=series.values, marker=dict(\n        color=series.values,\n        showscale=True\n    ))\n    layout = go.Layout(title=title)\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig, filename=filename)\n    \n    \nrender_bar_chart(train_df, 'diagnosis_label', 'Diabetic Retinopathy: Observation Distribution by Severity ', 'members')",
				"bm25Code": "# Reference: https://www.kaggle.com/code/gowrishankarin/diabetic-retinopathy-explore-plotly-cv2\n\ndef render_bar_chart(data_df, column_name, title, filename):\n    series = data_df[column_name].value_counts()\n    count = series.shape[0]\n    \n    trace = go.Bar(x = series.index, y=series.values, marker=dict(\n        color=series.values,\n        showscale=True\n    ))\n    layout = go.Layout(title=title)\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig, filename=filename)\n    \n    \nrender_bar_chart(train_df, 'diagnosis_label', 'Diabetic Retinopathy: Observation Distribution by Severity ', 'members')"
			}
		]
	}
}
